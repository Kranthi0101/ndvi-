{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Johnowhitaker\n",
    "# Required libraries\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "# Required libraries\n",
    "import tifffile as tiff\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API = 'YOUR KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these headers will be used in each request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API}',\n",
    "    'Accept':'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_url(item, asset_key, headers):\n",
    "    asset = item.get('assets', {}).get(asset_key, None)\n",
    "    if asset is None:\n",
    "        print(f'Asset \"{asset_key}\" does not exist in this item')\n",
    "        return None\n",
    "    r = requests.get(asset.get('href'), headers=headers, allow_redirects=False)\n",
    "    return r.headers.get('Location')\n",
    "\n",
    "def download_label(url, output_path, tileid):\n",
    "    filename = urlparse(url).path.split('/')[-1]\n",
    "    outpath = output_path/tileid\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    f = open(outpath/filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {filename}')\n",
    "    return \n",
    "\n",
    "def download_imagery(url, output_path, tileid, date):\n",
    "    filename = urlparse(url).path.split('/')[-1]\n",
    "    outpath = output_path/tileid/date\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    f = open(outpath/filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {filename}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the id of the labels collection:\n",
    "collectionId = 'ref_african_crops_kenya_02_labels'\n",
    "\n",
    "# these optional parameters can be used to control what items are returned. \n",
    "# Here, we want to download all the items so:\n",
    "limit = 100 \n",
    "bounding_box = []\n",
    "date_time = []\n",
    "\n",
    "# retrieves the items and their metadata in the collection\n",
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time}, headers=headers)\n",
    "collection = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve list of features (in this case tiles) in the collection\n",
    "for feature in collection.get('features', []):\n",
    "    assets = feature.get('assets').keys()\n",
    "    print(\"Feature\", feature.get('id'), 'with the following assets', list(assets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in collection.get('features', []):\n",
    "    \n",
    "    tileid = feature.get('id').split('tile_')[-1][:2]\n",
    "\n",
    "    # download labels\n",
    "    download_url = get_download_url(feature, 'labels', headers)\n",
    "    download_label(download_url, output_path, tileid)\n",
    "    \n",
    "    #download field_ids\n",
    "    download_url = get_download_url(feature, 'field_ids', headers)\n",
    "    download_label(download_url, output_path, tileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the id of the imagery collection:\n",
    "collectionId = 'ref_african_crops_kenya_02_source'\n",
    "\n",
    "# these optional parameters can be used to control what items are returned. \n",
    "# Here, we want to download all the items so:\n",
    "limit = 100 \n",
    "bounding_box = []\n",
    "date_time = []\n",
    "\n",
    "# retrieves the items and their metadata in the collection\n",
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time}, headers=headers)\n",
    "collection = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List assets of the items\n",
    "for feature in collection.get('features', []):\n",
    "    assets = feature.get('assets').keys()\n",
    "    print(list(assets))\n",
    "    break #all the features have the same type of assets. for simplicity we break the loop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell downloads all the multi-spectral images throughout the growing season for this competition.\n",
    "# The size of data is about 1.5 GB, and download time depends on your internet connection. \n",
    "# Note that you only need to run this cell and download the data once.\n",
    "i = 0\n",
    "for feature in collection.get('features', []):\n",
    "    assets = feature.get('assets').keys()\n",
    "    tileid = feature.get('id').split('tile_')[-1][:2]\n",
    "    date = datetime.strftime(datetime.strptime(feature.get('properties')['datetime'], \"%Y-%m-%dT%H:%M:%SZ\"), \"%Y%m%d\")\n",
    "    for asset in assets:\n",
    "        i += 1\n",
    "        if i > 0: # if resuming after it failed\n",
    "          download_url = get_download_url(feature, asset, headers)\n",
    "          download_imagery(download_url, output_path, tileid, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(fp):\n",
    "    \"\"\"Takes a PosixPath object or string filepath\n",
    "    and returns np array\"\"\"\n",
    "    \n",
    "    return tiff.imread(fp.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dates that an observation from Sentinel-2 is provided in the training dataset\n",
    "dates = [datetime.datetime(2019, 6, 6, 8, 10, 7),\n",
    "         datetime.datetime(2019, 7, 1, 8, 10, 4),\n",
    "         datetime.datetime(2019, 7, 6, 8, 10, 8),\n",
    "         datetime.datetime(2019, 7, 11, 8, 10, 4),\n",
    "         datetime.datetime(2019, 7, 21, 8, 10, 4),\n",
    "         datetime.datetime(2019, 8, 5, 8, 10, 7),\n",
    "         datetime.datetime(2019, 8, 15, 8, 10, 6),\n",
    "         datetime.datetime(2019, 8, 25, 8, 10, 4),\n",
    "         datetime.datetime(2019, 9, 9, 8, 9, 58),\n",
    "         datetime.datetime(2019, 9, 19, 8, 9, 59),\n",
    "         datetime.datetime(2019, 9, 24, 8, 9, 59),\n",
    "         datetime.datetime(2019, 10, 4, 8, 10),\n",
    "         datetime.datetime(2019, 11, 3, 8, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12', 'CLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample file to load:\n",
    "file_name = \"data/00/20190825/0_B03_20190825.tif\"\n",
    "band_data = load_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "plt.imshow(band_data, vmin=0, vmax=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick way to see an RGB image. Can mess with the scaling factor to change brightness (3 in this example)\n",
    "\n",
    "import numpy as np\n",
    "def load_rgb(tile, date):\n",
    "\n",
    "  r = load_file(f\"data/{tile}/{date}/{tile[1]}_B04_{date}.tif\")\n",
    "  g = load_file(f\"data/{tile}/{date}/{tile[1]}_B03_{date}.tif\")\n",
    "  b = load_file(f\"data/{tile}/{date}/{tile[1]}_B02_{date}.tif\")\n",
    "  arr = np.dstack((r, g, b))\n",
    "  print(max(g.flatten()))\n",
    "  return arr\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 18))\n",
    "ax.imshow(load_rgb('01', '20190825')*3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not super efficient but  ¯\\_(ツ)_/¯\n",
    "import pandas as pd\n",
    "\n",
    "row_locs = []\n",
    "col_locs = []\n",
    "field_ids = []\n",
    "labels = []\n",
    "tiles = []\n",
    "for tile in range(4):\n",
    "    fids = f'/content/data/0{tile}/{tile}_field_id.tif'\n",
    "    labs = f'/content/data/0{tile}/{tile}_label.tif'\n",
    "    fid_arr = load_file(fids)\n",
    "    lab_arr = load_file(labs)\n",
    "    for row in range(len(fid_arr)):\n",
    "        for col in range(len(fid_arr[0])):\n",
    "            if fid_arr[row][col] != 0:\n",
    "                row_locs.append(row)\n",
    "                col_locs.append(col)\n",
    "                field_ids.append(fid_arr[row][col])\n",
    "                labels.append(lab_arr[row][col])\n",
    "                tiles.append(tile)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'fid':field_ids,\n",
    "    'label':labels,\n",
    "    'row_loc': row_locs,\n",
    "    'col_loc':col_locs,\n",
    "    'tile':tiles\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "print(df.groupby('fid').count().shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Full_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
