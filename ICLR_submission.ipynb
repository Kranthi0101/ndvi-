{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "jbLexyD0U0jp",
    "outputId": "868db70e-27dc-4fd0-fd6a-ef0196385631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/ec/12b9a42b2ea7dfe5b602f235692ab2b61ee1334ff34334a15902272869e8/catboost-0.22-cp36-none-manylinux1_x86_64.whl (64.4MB)\n",
      "\u001b[K     |████████████████████████████████| 64.4MB 65kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (46.0.0)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.22\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aZR8ljxBhna6",
    "outputId": "37ccf939-7fac-4ce9-a5bc-db2c6cd5699a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/sample_data\n"
     ]
    }
   ],
   "source": [
    "cd sample_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "G1ZD4AWhhsr4",
    "outputId": "74711dc7-24d6-4d6a-f5e7-ab19b470b734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Full_data.zip\n",
      "  inflating: Full_data.csv           \n"
     ]
    }
   ],
   "source": [
    "!unzip Full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lTl_ktwkhsui"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#-------------------------------------------------\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "#---------------------------------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "# from featexp import get_univariate_plots\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "mMfOlxi7hsyW",
    "outputId": "58f52c06-72b1-4dd6-8fab-9917018f7687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67557, 174)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>label</th>\n",
       "      <th>row_loc</th>\n",
       "      <th>col_loc</th>\n",
       "      <th>tile</th>\n",
       "      <th>20190606_B01</th>\n",
       "      <th>20190606_B02</th>\n",
       "      <th>20190606_B03</th>\n",
       "      <th>20190606_B04</th>\n",
       "      <th>20190606_B05</th>\n",
       "      <th>20190606_B06</th>\n",
       "      <th>20190606_B07</th>\n",
       "      <th>20190606_B08</th>\n",
       "      <th>20190606_B8A</th>\n",
       "      <th>20190606_B09</th>\n",
       "      <th>20190606_B11</th>\n",
       "      <th>20190606_B12</th>\n",
       "      <th>20190606_CLD</th>\n",
       "      <th>20190701_B01</th>\n",
       "      <th>20190701_B02</th>\n",
       "      <th>20190701_B03</th>\n",
       "      <th>20190701_B04</th>\n",
       "      <th>20190701_B05</th>\n",
       "      <th>20190701_B06</th>\n",
       "      <th>20190701_B07</th>\n",
       "      <th>20190701_B08</th>\n",
       "      <th>20190701_B8A</th>\n",
       "      <th>20190701_B09</th>\n",
       "      <th>20190701_B11</th>\n",
       "      <th>20190701_B12</th>\n",
       "      <th>20190701_CLD</th>\n",
       "      <th>20190706_B01</th>\n",
       "      <th>20190706_B02</th>\n",
       "      <th>20190706_B03</th>\n",
       "      <th>20190706_B04</th>\n",
       "      <th>20190706_B05</th>\n",
       "      <th>20190706_B06</th>\n",
       "      <th>20190706_B07</th>\n",
       "      <th>20190706_B08</th>\n",
       "      <th>20190706_B8A</th>\n",
       "      <th>...</th>\n",
       "      <th>20190919_CLD</th>\n",
       "      <th>20190924_B01</th>\n",
       "      <th>20190924_B02</th>\n",
       "      <th>20190924_B03</th>\n",
       "      <th>20190924_B04</th>\n",
       "      <th>20190924_B05</th>\n",
       "      <th>20190924_B06</th>\n",
       "      <th>20190924_B07</th>\n",
       "      <th>20190924_B08</th>\n",
       "      <th>20190924_B8A</th>\n",
       "      <th>20190924_B09</th>\n",
       "      <th>20190924_B11</th>\n",
       "      <th>20190924_B12</th>\n",
       "      <th>20190924_CLD</th>\n",
       "      <th>20191004_B01</th>\n",
       "      <th>20191004_B02</th>\n",
       "      <th>20191004_B03</th>\n",
       "      <th>20191004_B04</th>\n",
       "      <th>20191004_B05</th>\n",
       "      <th>20191004_B06</th>\n",
       "      <th>20191004_B07</th>\n",
       "      <th>20191004_B08</th>\n",
       "      <th>20191004_B8A</th>\n",
       "      <th>20191004_B09</th>\n",
       "      <th>20191004_B11</th>\n",
       "      <th>20191004_B12</th>\n",
       "      <th>20191004_CLD</th>\n",
       "      <th>20191103_B01</th>\n",
       "      <th>20191103_B02</th>\n",
       "      <th>20191103_B03</th>\n",
       "      <th>20191103_B04</th>\n",
       "      <th>20191103_B05</th>\n",
       "      <th>20191103_B06</th>\n",
       "      <th>20191103_B07</th>\n",
       "      <th>20191103_B08</th>\n",
       "      <th>20191103_B8A</th>\n",
       "      <th>20191103_B09</th>\n",
       "      <th>20191103_B11</th>\n",
       "      <th>20191103_B12</th>\n",
       "      <th>20191103_CLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2928</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>1278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.4149</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.3099</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.3427</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.3204</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2928</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>1279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.3859</td>\n",
       "      <td>0.4149</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.3127</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.3427</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2928</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.4101</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2928</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.3869</td>\n",
       "      <td>0.4101</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.1214</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.2861</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2928</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.3662</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.4073</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.3567</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fid  label  row_loc  ...  20191103_B11  20191103_B12  20191103_CLD\n",
       "0  2928      4      214  ...        0.2362        0.1347           0.0\n",
       "1  2928      4      214  ...        0.2362        0.1347           0.0\n",
       "2  2928      4      214  ...        0.2304        0.1471           0.0\n",
       "3  2928      4      214  ...        0.2304        0.1471           0.0\n",
       "4  2928      4      214  ...        0.2323        0.1355           0.0\n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('Full_data.csv')\n",
    "Full_data = df\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vylt2umHhs_b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# NDVI :(B8A-B04)/(B8A+B04)\n",
    "B8A_features =  df.filter(regex='._B8A')\n",
    "B8A_features_col = B8A_features.columns\n",
    "B04_features =  df.filter(regex='._B04')\n",
    "B04_features_col = B04_features.columns\n",
    "NDVI = []\n",
    "for i in range(13) :\n",
    "    NDVI.append('{}_NDVI'.format(i))\n",
    "    B8A = '{}'.format(B8A_features_col[i])\n",
    "    B04 = '{}'.format(B04_features_col[i])\n",
    "    df['{}_NDVI'.format(i)] = (df[B8A]-df[B04])/(df[B8A]+df[B04])\n",
    "pca=PCA(1)\n",
    "df[\"NDVI\"]=pca.fit_transform(df[NDVI])  \n",
    "df['F_NDVI'] =  df.groupby('NDVI')['fid'].transform('mean')\n",
    "df['water'] = df['0_NDVI'].apply(lambda x :1 if x<0 else 0)\n",
    "df['dense_green'] = df['0_NDVI'].apply(lambda x :1 if x>=0.5 else 0)\n",
    "df['not_green'] = df['0_NDVI'].apply(lambda x :1 if( (x>0) & (x<0.5)) else 0)\n",
    "# df = df.drop(NDVI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QLH-KerhtEN"
   },
   "outputs": [],
   "source": [
    "# # SAVI :1.5*(B8A-B04)/(B8A+B04+0.5)\n",
    "SAVI = []\n",
    "for i in range(13) :\n",
    "    SAVI.append('{}_SAVI'.format(i))\n",
    "    df['{}_SAVI'.format(i)] = 1.5*(Full_data[B8A]-Full_data[B04])/(Full_data[B8A]+Full_data[B04]+0.5)\n",
    "pca=PCA(1)\n",
    "df[\"SAVI\"]=pca.fit_transform(df[SAVI])\n",
    "df['high_green'] = df['0_SAVI'].apply(lambda x :1 if x<0.1 else 0)\n",
    "df['low_green'] = df['0_SAVI'].apply(lambda x :1 if x>=0.8 else 0)\n",
    "df = df.drop(SAVI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzkxsARPhtVQ"
   },
   "outputs": [],
   "source": [
    "#RECI :(B08/B04)-1\n",
    "B08_features =  df.filter(regex='._B08')\n",
    "B08_features_col = B08_features.columns\n",
    "RECI = []\n",
    "for i in range(13) :\n",
    "    RECI.append('{}_RECI'.format(i))\n",
    "    B08 = '{}'.format(B08_features_col[i])\n",
    "    df['{}_RECI'.format(i)] = ((Full_data[B08])/(Full_data[B04]))-1\n",
    "pca=PCA(1)\n",
    "df[\"RECI\"]=pca.fit_transform(df[RECI])    \n",
    "df = df.drop(RECI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aU-YTv9chtbb"
   },
   "outputs": [],
   "source": [
    "columns=['20190606_B04','20190606_B8A', '20190701_B04',\n",
    "       '20190701_B8A', '20190706_B8A',  '20190711_B04','20190711_B8A', '20190721_B04', '20190721_B8A',\n",
    "        '20190805_B04', '20190805_B8A','20190815_B04', '20190815_B8A',\n",
    "      '20190825_B04','20190825_B8A','20190909_B04',  '20190909_B8A',  '20190919_B04', '20190919_B8A',\n",
    "         '20190924_B04',  '20190924_B8A',\n",
    "       '20191004_B04','20191004_B8A', '20191103_B04',  '20191103_B8A', ]\n",
    "data = df[columns].copy()\n",
    "km=KMeans(5,random_state=2019)\n",
    "df[\"cluster_3\"]=km.fit_predict(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNatn0GfhtnK"
   },
   "outputs": [],
   "source": [
    "columns_2=df.drop(['fid','label', 'row_loc', 'col_loc', 'tile'],1).columns\n",
    "data_2 = df[columns_2].copy()\n",
    "km_2=KMeans(20,random_state=2019)\n",
    "# df[\"cluster_1\"]=km_2.fit_predict(data_2[columns_2])\n",
    "df[\"cluster_2\"]=km_2.fit_predict(data_2[columns_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_QSs4gLhtkn"
   },
   "outputs": [],
   "source": [
    "# df['SAVI_en'] = df.groupby('SAVI')['cluster_2'].transform('mean')\n",
    "# df['RECI_en_2'] = df.groupby('NDVI')['cluster_2'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xU_YBRqkhtiV"
   },
   "outputs": [],
   "source": [
    "# MSI :B11/B8A\n",
    "B11_features =  df.filter(regex='._B11')\n",
    "B11_features_col = B11_features.columns\n",
    "MSI = []\n",
    "for i in range(13) :\n",
    "    MSI.append('{}_MSI'.format(i))\n",
    "    B8A = '{}'.format(B8A_features_col[i])\n",
    "    B11 = '{}'.format(B04_features_col[i])\n",
    "    df['{}_MSI'.format(i)] = (Full_data[B11])/(Full_data[B8A])\n",
    "pca=PCA(1)\n",
    "df[\"MSI\"]=pca.fit_transform(df[MSI])  \n",
    "df = df.drop('F_NDVI',1)\n",
    "# df = df.drop(MSI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Hq8TasdhtgY"
   },
   "outputs": [],
   "source": [
    "# NDRE :(B09-B05)/(B09+B05)\n",
    "B09_features =  df.filter(regex='._B09')\n",
    "B09_features_col = B09_features.columns\n",
    "B05_features =  df.filter(regex='._B05')\n",
    "B05_features_col = B05_features.columns\n",
    "NDRE = []\n",
    "for i in range(13) :\n",
    "    NDRE.append('{}_NDRE'.format(i))\n",
    "    B09 = '{}'.format(B09_features_col[i])\n",
    "    B05 = '{}'.format(B05_features_col[i])\n",
    "    df['{}_NDRE'.format(i)] =  (Full_data[B09]-Full_data[B05])/(Full_data[B09]+Full_data[B05])\n",
    "pca=PCA(1)\n",
    "df[\"NDRE\"]=pca.fit_transform(df[NDRE])  \n",
    "# df = df.drop(NDRE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DJdVdIJhtYr"
   },
   "outputs": [],
   "source": [
    "# ARVI :(B08-(B04-1*(B02-B04)))/(B08+(B04-1*(B02-B04)))\n",
    "B02_features =  df.filter(regex='._B02')\n",
    "B02_features_col = B02_features.columns\n",
    "ARVI = []\n",
    "for i in range(13) :\n",
    "    ARVI.append('{}_ARVI'.format(i))\n",
    "    B08 = '{}'.format(B08_features_col[i])\n",
    "    B04 = '{}'.format(B04_features_col[i])\n",
    "    B02 = '{}'.format(B02_features_col[i])\n",
    "    df['{}_ARVI'.format(i)] = (Full_data[B08]-(Full_data[B04]-1*(Full_data[B02]-Full_data[B04])))/(Full_data[B08]+(Full_data[B04]-1*(Full_data[B02]-Full_data[B04])))\n",
    "pca=PCA(1)\n",
    "df[\"ARVI\"]=pca.fit_transform(df[ARVI])  \n",
    "# df = df.drop(NDRE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Y3ykiZJhtTy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# FIDET : B12/(B8A*B09)\n",
    "B12_features =  df.filter(regex='._B12')\n",
    "B12_features_col = B11_features.columns\n",
    "FIDET = []\n",
    "for i in range(13) :\n",
    "    FIDET.append('{}_FIDET'.format(i))\n",
    "    B12 = '{}'.format(B12_features_col[i])\n",
    "    df['{}_FIDET'.format(i)] =  (Full_data[B12])/(Full_data[B8A]*Full_data[B09])\n",
    "pca=PCA(1)\n",
    "df[\"FIDET\"]=pca.fit_transform(df[FIDET])  \n",
    "# df = df.drop(MSI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhNkKRpohtPn"
   },
   "outputs": [],
   "source": [
    "df['RECI_en'] = df.groupby('NDVI')['cluster_3'].transform('mean')\n",
    "df['MSI_en'] = df.groupby('MSI')['cluster_3'].transform('mean')\n",
    "df['NDRE_en'] = df.groupby('NDRE')['cluster_3'].transform('mean')\n",
    "df['NDRE_en'] = df.groupby('NDRE')['cluster_3'].transform('mean')\n",
    "df['FIDET_en'] = df.groupby('FIDET')['cluster_3'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UF2nAJABhtM_"
   },
   "outputs": [],
   "source": [
    "#EVI :2.5*((B8A-B04)/(B8A+6*B04-7.5*B02+1))\n",
    "EVI = []\n",
    "for i in range(13) :\n",
    "    EVI.append('{}_EVI'.format(i))\n",
    "    B8A = '{}'.format(B8A_features_col[i])\n",
    "    B04 = '{}'.format(B04_features_col[i])\n",
    "    B02 = '{}'.format(B02_features_col[i])\n",
    "    df['{}_EVI'.format(i)] = 2.5*((Full_data[B8A]-Full_data[B04])/(Full_data[B8A]+6*Full_data[B04]-7.5*Full_data[B02]+1))\n",
    "pca=PCA(1)\n",
    "df[\"EVI\"]=pca.fit_transform(df[EVI])  \n",
    "df['chlorophyll_EVI'] = df['0_EVI'].apply(lambda x :1 if( (x>0.2) & (x<0.8)) else 0)\n",
    "# df = df.drop(EVI,1)chlorophyll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3Qu-h0ahtK9"
   },
   "outputs": [],
   "source": [
    "#SIPI : (B08-B02)/(B08-B04)\n",
    "SIPI = []\n",
    "for i in range(13) :\n",
    "    SIPI.append('{}_SIPI'.format(i))\n",
    "    B08 = '{}'.format(B08_features_col[i])\n",
    "    B04 = '{}'.format(B04_features_col[i])\n",
    "    B02 = '{}'.format(B02_features_col[i])\n",
    "    df['{}_SIPI'.format(i)] = (Full_data[B08]-Full_data[B02])/(Full_data[B08]-Full_data[B04])\n",
    "pca=PCA(1)\n",
    "# df[\"SIPI\"]=pca.fit_transform(df[SIPI])\n",
    "df['carotenoids'] = df['0_SIPI'].apply(lambda x :1 if x>0 else 0)\n",
    "df['chlorophyll-SIPI'] = df['0_SIPI'].apply(lambda x :1 if x<=0 else 0)  \n",
    "# df = df.drop(SIPI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9vSRjByshtI1",
    "outputId": "0c87f6ec-abf7-4b36-d4e9-87442101c6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47791, 287)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9my2RbnShs7-",
    "outputId": "3c08a44c-198a-4b84-8aee-8c74d20b198f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8633567\ttotal: 1.56s\tremaining: 25m 58s\n",
      "1:\tlearn: 1.7859124\ttotal: 3.03s\tremaining: 25m 11s\n",
      "2:\tlearn: 1.7115240\ttotal: 4.52s\tremaining: 25m 1s\n",
      "3:\tlearn: 1.6162104\ttotal: 5.93s\tremaining: 24m 36s\n",
      "4:\tlearn: 1.5571744\ttotal: 7.26s\tremaining: 24m 4s\n",
      "5:\tlearn: 1.4962117\ttotal: 8.61s\tremaining: 23m 46s\n",
      "6:\tlearn: 1.4565056\ttotal: 9.93s\tremaining: 23m 28s\n",
      "7:\tlearn: 1.4220450\ttotal: 11.3s\tremaining: 23m 18s\n",
      "8:\tlearn: 1.3869449\ttotal: 12.6s\tremaining: 23m 7s\n",
      "9:\tlearn: 1.3583433\ttotal: 14s\tremaining: 23m 3s\n",
      "10:\tlearn: 1.3319914\ttotal: 15.3s\tremaining: 22m 57s\n",
      "11:\tlearn: 1.3038857\ttotal: 16.7s\tremaining: 22m 51s\n",
      "12:\tlearn: 1.2670686\ttotal: 18s\tremaining: 22m 46s\n",
      "13:\tlearn: 1.2451340\ttotal: 19.3s\tremaining: 22m 36s\n",
      "14:\tlearn: 1.2251452\ttotal: 20.5s\tremaining: 22m 25s\n",
      "15:\tlearn: 1.2018027\ttotal: 21.7s\tremaining: 22m 13s\n",
      "16:\tlearn: 1.1784331\ttotal: 22.9s\tremaining: 22m 5s\n",
      "17:\tlearn: 1.1608367\ttotal: 24.1s\tremaining: 21m 56s\n",
      "18:\tlearn: 1.1429572\ttotal: 25.4s\tremaining: 21m 49s\n",
      "19:\tlearn: 1.1277558\ttotal: 26.6s\tremaining: 21m 44s\n",
      "20:\tlearn: 1.1135587\ttotal: 27.9s\tremaining: 21m 38s\n",
      "21:\tlearn: 1.1013454\ttotal: 29.1s\tremaining: 21m 33s\n",
      "22:\tlearn: 1.0817748\ttotal: 30.4s\tremaining: 21m 29s\n",
      "23:\tlearn: 1.0673606\ttotal: 31.6s\tremaining: 21m 26s\n",
      "24:\tlearn: 1.0567446\ttotal: 32.9s\tremaining: 21m 22s\n",
      "25:\tlearn: 1.0453487\ttotal: 34.2s\tremaining: 21m 19s\n",
      "26:\tlearn: 1.0354827\ttotal: 35.5s\tremaining: 21m 18s\n",
      "27:\tlearn: 1.0194539\ttotal: 36.9s\tremaining: 21m 19s\n",
      "28:\tlearn: 1.0097042\ttotal: 38.3s\tremaining: 21m 23s\n",
      "29:\tlearn: 1.0011534\ttotal: 39.7s\tremaining: 21m 25s\n",
      "30:\tlearn: 0.9926469\ttotal: 41.3s\tremaining: 21m 31s\n",
      "31:\tlearn: 0.9788873\ttotal: 42.9s\tremaining: 21m 36s\n",
      "32:\tlearn: 0.9699370\ttotal: 44.4s\tremaining: 21m 40s\n",
      "33:\tlearn: 0.9620297\ttotal: 45.9s\tremaining: 21m 43s\n",
      "34:\tlearn: 0.9539662\ttotal: 47.3s\tremaining: 21m 45s\n",
      "35:\tlearn: 0.9458716\ttotal: 48.9s\tremaining: 21m 48s\n",
      "36:\tlearn: 0.9383448\ttotal: 50.4s\tremaining: 21m 50s\n",
      "37:\tlearn: 0.9293888\ttotal: 51.9s\tremaining: 21m 53s\n",
      "38:\tlearn: 0.9217724\ttotal: 53.4s\tremaining: 21m 55s\n",
      "39:\tlearn: 0.9126959\ttotal: 54.9s\tremaining: 21m 58s\n",
      "40:\tlearn: 0.9068740\ttotal: 56.5s\tremaining: 22m 1s\n",
      "41:\tlearn: 0.8991889\ttotal: 58s\tremaining: 22m 2s\n",
      "42:\tlearn: 0.8921228\ttotal: 59.5s\tremaining: 22m 5s\n",
      "43:\tlearn: 0.8858371\ttotal: 1m 1s\tremaining: 22m 6s\n",
      "44:\tlearn: 0.8795324\ttotal: 1m 2s\tremaining: 22m 7s\n",
      "45:\tlearn: 0.8738267\ttotal: 1m 3s\tremaining: 22m 6s\n",
      "46:\tlearn: 0.8691604\ttotal: 1m 5s\tremaining: 22m 3s\n",
      "47:\tlearn: 0.8586847\ttotal: 1m 6s\tremaining: 22m\n",
      "48:\tlearn: 0.8517252\ttotal: 1m 7s\tremaining: 21m 58s\n",
      "49:\tlearn: 0.8468437\ttotal: 1m 9s\tremaining: 21m 55s\n",
      "50:\tlearn: 0.8426943\ttotal: 1m 10s\tremaining: 21m 54s\n",
      "51:\tlearn: 0.8359411\ttotal: 1m 12s\tremaining: 21m 52s\n",
      "52:\tlearn: 0.8300655\ttotal: 1m 13s\tremaining: 21m 49s\n",
      "53:\tlearn: 0.8242725\ttotal: 1m 14s\tremaining: 21m 45s\n",
      "54:\tlearn: 0.8179119\ttotal: 1m 15s\tremaining: 21m 41s\n",
      "55:\tlearn: 0.8122745\ttotal: 1m 17s\tremaining: 21m 39s\n",
      "56:\tlearn: 0.8048084\ttotal: 1m 18s\tremaining: 21m 37s\n",
      "57:\tlearn: 0.7983256\ttotal: 1m 19s\tremaining: 21m 34s\n",
      "58:\tlearn: 0.7936660\ttotal: 1m 21s\tremaining: 21m 32s\n",
      "59:\tlearn: 0.7872565\ttotal: 1m 22s\tremaining: 21m 31s\n",
      "60:\tlearn: 0.7814906\ttotal: 1m 23s\tremaining: 21m 28s\n",
      "61:\tlearn: 0.7755080\ttotal: 1m 25s\tremaining: 21m 26s\n",
      "62:\tlearn: 0.7713608\ttotal: 1m 26s\tremaining: 21m 23s\n",
      "63:\tlearn: 0.7659273\ttotal: 1m 27s\tremaining: 21m 21s\n",
      "64:\tlearn: 0.7603606\ttotal: 1m 29s\tremaining: 21m 20s\n",
      "65:\tlearn: 0.7555182\ttotal: 1m 30s\tremaining: 21m 19s\n",
      "66:\tlearn: 0.7514669\ttotal: 1m 31s\tremaining: 21m 18s\n",
      "67:\tlearn: 0.7467771\ttotal: 1m 33s\tremaining: 21m 18s\n",
      "68:\tlearn: 0.7414307\ttotal: 1m 34s\tremaining: 21m 17s\n",
      "69:\tlearn: 0.7361440\ttotal: 1m 36s\tremaining: 21m 17s\n",
      "70:\tlearn: 0.7309952\ttotal: 1m 37s\tremaining: 21m 16s\n",
      "71:\tlearn: 0.7267362\ttotal: 1m 39s\tremaining: 21m 16s\n",
      "72:\tlearn: 0.7228148\ttotal: 1m 40s\tremaining: 21m 16s\n",
      "73:\tlearn: 0.7191772\ttotal: 1m 41s\tremaining: 21m 15s\n",
      "74:\tlearn: 0.7150625\ttotal: 1m 43s\tremaining: 21m 15s\n",
      "75:\tlearn: 0.7102857\ttotal: 1m 44s\tremaining: 21m 13s\n",
      "76:\tlearn: 0.7038718\ttotal: 1m 46s\tremaining: 21m 11s\n",
      "77:\tlearn: 0.7011958\ttotal: 1m 47s\tremaining: 21m 9s\n",
      "78:\tlearn: 0.6971684\ttotal: 1m 48s\tremaining: 21m 5s\n",
      "79:\tlearn: 0.6903850\ttotal: 1m 49s\tremaining: 21m 2s\n",
      "80:\tlearn: 0.6866087\ttotal: 1m 51s\tremaining: 20m 59s\n",
      "81:\tlearn: 0.6816631\ttotal: 1m 52s\tremaining: 20m 56s\n",
      "82:\tlearn: 0.6763641\ttotal: 1m 53s\tremaining: 20m 53s\n",
      "83:\tlearn: 0.6720111\ttotal: 1m 54s\tremaining: 20m 50s\n",
      "84:\tlearn: 0.6691184\ttotal: 1m 55s\tremaining: 20m 47s\n",
      "85:\tlearn: 0.6651548\ttotal: 1m 57s\tremaining: 20m 44s\n",
      "86:\tlearn: 0.6608946\ttotal: 1m 58s\tremaining: 20m 41s\n",
      "87:\tlearn: 0.6563148\ttotal: 1m 59s\tremaining: 20m 39s\n",
      "88:\tlearn: 0.6518378\ttotal: 2m\tremaining: 20m 36s\n",
      "89:\tlearn: 0.6465911\ttotal: 2m 2s\tremaining: 20m 34s\n",
      "90:\tlearn: 0.6438710\ttotal: 2m 3s\tremaining: 20m 31s\n",
      "91:\tlearn: 0.6387544\ttotal: 2m 4s\tremaining: 20m 29s\n",
      "92:\tlearn: 0.6351025\ttotal: 2m 5s\tremaining: 20m 26s\n",
      "93:\tlearn: 0.6314746\ttotal: 2m 7s\tremaining: 20m 24s\n",
      "94:\tlearn: 0.6272036\ttotal: 2m 8s\tremaining: 20m 22s\n",
      "95:\tlearn: 0.6231230\ttotal: 2m 9s\tremaining: 20m 20s\n",
      "96:\tlearn: 0.6189810\ttotal: 2m 10s\tremaining: 20m 19s\n",
      "97:\tlearn: 0.6153503\ttotal: 2m 12s\tremaining: 20m 17s\n",
      "98:\tlearn: 0.6099422\ttotal: 2m 13s\tremaining: 20m 15s\n",
      "99:\tlearn: 0.6041353\ttotal: 2m 14s\tremaining: 20m 14s\n",
      "100:\tlearn: 0.6010591\ttotal: 2m 16s\tremaining: 20m 12s\n",
      "101:\tlearn: 0.5976754\ttotal: 2m 17s\tremaining: 20m 10s\n",
      "102:\tlearn: 0.5936827\ttotal: 2m 18s\tremaining: 20m 9s\n",
      "103:\tlearn: 0.5908301\ttotal: 2m 20s\tremaining: 20m 7s\n",
      "104:\tlearn: 0.5878022\ttotal: 2m 21s\tremaining: 20m 6s\n",
      "105:\tlearn: 0.5831686\ttotal: 2m 22s\tremaining: 20m 4s\n",
      "106:\tlearn: 0.5804453\ttotal: 2m 24s\tremaining: 20m 3s\n",
      "107:\tlearn: 0.5772929\ttotal: 2m 25s\tremaining: 20m 1s\n",
      "108:\tlearn: 0.5732909\ttotal: 2m 26s\tremaining: 20m 1s\n",
      "109:\tlearn: 0.5695163\ttotal: 2m 28s\tremaining: 20m\n",
      "110:\tlearn: 0.5660869\ttotal: 2m 29s\tremaining: 20m\n",
      "111:\tlearn: 0.5630804\ttotal: 2m 31s\tremaining: 20m\n",
      "112:\tlearn: 0.5594729\ttotal: 2m 32s\tremaining: 20m\n",
      "113:\tlearn: 0.5556044\ttotal: 2m 34s\tremaining: 20m\n",
      "114:\tlearn: 0.5520562\ttotal: 2m 35s\tremaining: 19m 59s\n",
      "115:\tlearn: 0.5495521\ttotal: 2m 37s\tremaining: 19m 58s\n",
      "116:\tlearn: 0.5471998\ttotal: 2m 38s\tremaining: 19m 57s\n",
      "117:\tlearn: 0.5442446\ttotal: 2m 40s\tremaining: 19m 56s\n",
      "118:\tlearn: 0.5404692\ttotal: 2m 41s\tremaining: 19m 55s\n",
      "119:\tlearn: 0.5381608\ttotal: 2m 42s\tremaining: 19m 54s\n",
      "120:\tlearn: 0.5333331\ttotal: 2m 44s\tremaining: 19m 52s\n",
      "121:\tlearn: 0.5303389\ttotal: 2m 45s\tremaining: 19m 50s\n",
      "122:\tlearn: 0.5271845\ttotal: 2m 46s\tremaining: 19m 48s\n",
      "123:\tlearn: 0.5227201\ttotal: 2m 48s\tremaining: 19m 47s\n",
      "124:\tlearn: 0.5205789\ttotal: 2m 49s\tremaining: 19m 45s\n",
      "125:\tlearn: 0.5179403\ttotal: 2m 50s\tremaining: 19m 43s\n",
      "126:\tlearn: 0.5151568\ttotal: 2m 52s\tremaining: 19m 42s\n",
      "127:\tlearn: 0.5120738\ttotal: 2m 53s\tremaining: 19m 40s\n",
      "128:\tlearn: 0.5096383\ttotal: 2m 54s\tremaining: 19m 40s\n",
      "129:\tlearn: 0.5063169\ttotal: 2m 56s\tremaining: 19m 39s\n",
      "130:\tlearn: 0.5036381\ttotal: 2m 57s\tremaining: 19m 37s\n",
      "131:\tlearn: 0.5009919\ttotal: 2m 58s\tremaining: 19m 36s\n",
      "132:\tlearn: 0.4990850\ttotal: 3m\tremaining: 19m 35s\n",
      "133:\tlearn: 0.4963428\ttotal: 3m 1s\tremaining: 19m 34s\n",
      "134:\tlearn: 0.4931998\ttotal: 3m 3s\tremaining: 19m 32s\n",
      "135:\tlearn: 0.4916835\ttotal: 3m 4s\tremaining: 19m 31s\n",
      "136:\tlearn: 0.4882930\ttotal: 3m 5s\tremaining: 19m 30s\n",
      "137:\tlearn: 0.4860339\ttotal: 3m 7s\tremaining: 19m 29s\n",
      "138:\tlearn: 0.4831796\ttotal: 3m 8s\tremaining: 19m 28s\n",
      "139:\tlearn: 0.4791506\ttotal: 3m 9s\tremaining: 19m 27s\n",
      "140:\tlearn: 0.4764328\ttotal: 3m 11s\tremaining: 19m 25s\n",
      "141:\tlearn: 0.4744879\ttotal: 3m 12s\tremaining: 19m 24s\n",
      "142:\tlearn: 0.4725268\ttotal: 3m 14s\tremaining: 19m 23s\n",
      "143:\tlearn: 0.4697189\ttotal: 3m 15s\tremaining: 19m 22s\n",
      "144:\tlearn: 0.4654814\ttotal: 3m 16s\tremaining: 19m 21s\n",
      "145:\tlearn: 0.4637637\ttotal: 3m 18s\tremaining: 19m 20s\n",
      "146:\tlearn: 0.4614172\ttotal: 3m 19s\tremaining: 19m 19s\n",
      "147:\tlearn: 0.4588481\ttotal: 3m 21s\tremaining: 19m 18s\n",
      "148:\tlearn: 0.4563234\ttotal: 3m 22s\tremaining: 19m 16s\n",
      "149:\tlearn: 0.4541979\ttotal: 3m 23s\tremaining: 19m 15s\n",
      "150:\tlearn: 0.4520028\ttotal: 3m 25s\tremaining: 19m 14s\n",
      "151:\tlearn: 0.4498871\ttotal: 3m 26s\tremaining: 19m 13s\n",
      "152:\tlearn: 0.4475669\ttotal: 3m 28s\tremaining: 19m 12s\n",
      "153:\tlearn: 0.4446158\ttotal: 3m 29s\tremaining: 19m 11s\n",
      "154:\tlearn: 0.4415227\ttotal: 3m 31s\tremaining: 19m 10s\n",
      "155:\tlearn: 0.4385343\ttotal: 3m 32s\tremaining: 19m 9s\n",
      "156:\tlearn: 0.4356324\ttotal: 3m 33s\tremaining: 19m 7s\n",
      "157:\tlearn: 0.4335165\ttotal: 3m 35s\tremaining: 19m 6s\n",
      "158:\tlearn: 0.4313997\ttotal: 3m 36s\tremaining: 19m 5s\n",
      "159:\tlearn: 0.4297037\ttotal: 3m 38s\tremaining: 19m 4s\n",
      "160:\tlearn: 0.4274680\ttotal: 3m 39s\tremaining: 19m 3s\n",
      "161:\tlearn: 0.4253505\ttotal: 3m 40s\tremaining: 19m 2s\n",
      "162:\tlearn: 0.4244756\ttotal: 3m 42s\tremaining: 19m 1s\n",
      "163:\tlearn: 0.4225516\ttotal: 3m 43s\tremaining: 19m\n",
      "164:\tlearn: 0.4198480\ttotal: 3m 45s\tremaining: 18m 59s\n",
      "165:\tlearn: 0.4176988\ttotal: 3m 46s\tremaining: 18m 58s\n",
      "166:\tlearn: 0.4158362\ttotal: 3m 48s\tremaining: 18m 57s\n",
      "167:\tlearn: 0.4145108\ttotal: 3m 49s\tremaining: 18m 56s\n",
      "168:\tlearn: 0.4110706\ttotal: 3m 51s\tremaining: 18m 57s\n",
      "169:\tlearn: 0.4092163\ttotal: 3m 52s\tremaining: 18m 56s\n",
      "170:\tlearn: 0.4068915\ttotal: 3m 54s\tremaining: 18m 55s\n",
      "171:\tlearn: 0.4051871\ttotal: 3m 55s\tremaining: 18m 54s\n",
      "172:\tlearn: 0.4029360\ttotal: 3m 57s\tremaining: 18m 53s\n",
      "173:\tlearn: 0.4006051\ttotal: 3m 58s\tremaining: 18m 52s\n",
      "174:\tlearn: 0.3992362\ttotal: 3m 59s\tremaining: 18m 50s\n",
      "175:\tlearn: 0.3958357\ttotal: 4m 1s\tremaining: 18m 49s\n",
      "176:\tlearn: 0.3944263\ttotal: 4m 2s\tremaining: 18m 48s\n",
      "177:\tlearn: 0.3916080\ttotal: 4m 4s\tremaining: 18m 47s\n",
      "178:\tlearn: 0.3903565\ttotal: 4m 5s\tremaining: 18m 46s\n",
      "179:\tlearn: 0.3882306\ttotal: 4m 6s\tremaining: 18m 44s\n",
      "180:\tlearn: 0.3862555\ttotal: 4m 8s\tremaining: 18m 43s\n",
      "181:\tlearn: 0.3842778\ttotal: 4m 9s\tremaining: 18m 42s\n",
      "182:\tlearn: 0.3820370\ttotal: 4m 11s\tremaining: 18m 41s\n",
      "183:\tlearn: 0.3801236\ttotal: 4m 12s\tremaining: 18m 40s\n",
      "184:\tlearn: 0.3781757\ttotal: 4m 13s\tremaining: 18m 38s\n",
      "185:\tlearn: 0.3769032\ttotal: 4m 15s\tremaining: 18m 36s\n",
      "186:\tlearn: 0.3742945\ttotal: 4m 16s\tremaining: 18m 34s\n",
      "187:\tlearn: 0.3720690\ttotal: 4m 17s\tremaining: 18m 32s\n",
      "188:\tlearn: 0.3700625\ttotal: 4m 18s\tremaining: 18m 30s\n",
      "189:\tlearn: 0.3686226\ttotal: 4m 20s\tremaining: 18m 28s\n",
      "190:\tlearn: 0.3663264\ttotal: 4m 21s\tremaining: 18m 26s\n",
      "191:\tlearn: 0.3647487\ttotal: 4m 22s\tremaining: 18m 25s\n",
      "192:\tlearn: 0.3634883\ttotal: 4m 24s\tremaining: 18m 24s\n",
      "193:\tlearn: 0.3621465\ttotal: 4m 25s\tremaining: 18m 23s\n",
      "194:\tlearn: 0.3606210\ttotal: 4m 27s\tremaining: 18m 22s\n",
      "195:\tlearn: 0.3592106\ttotal: 4m 28s\tremaining: 18m 21s\n",
      "196:\tlearn: 0.3571270\ttotal: 4m 29s\tremaining: 18m 20s\n",
      "197:\tlearn: 0.3554088\ttotal: 4m 31s\tremaining: 18m 19s\n",
      "198:\tlearn: 0.3534609\ttotal: 4m 32s\tremaining: 18m 18s\n",
      "199:\tlearn: 0.3510070\ttotal: 4m 34s\tremaining: 18m 17s\n",
      "200:\tlearn: 0.3494454\ttotal: 4m 36s\tremaining: 18m 17s\n",
      "201:\tlearn: 0.3476957\ttotal: 4m 37s\tremaining: 18m 17s\n",
      "202:\tlearn: 0.3458669\ttotal: 4m 39s\tremaining: 18m 16s\n",
      "203:\tlearn: 0.3444330\ttotal: 4m 40s\tremaining: 18m 15s\n",
      "204:\tlearn: 0.3424278\ttotal: 4m 42s\tremaining: 18m 15s\n",
      "205:\tlearn: 0.3410266\ttotal: 4m 43s\tremaining: 18m 14s\n",
      "206:\tlearn: 0.3392284\ttotal: 4m 45s\tremaining: 18m 12s\n",
      "207:\tlearn: 0.3381219\ttotal: 4m 46s\tremaining: 18m 11s\n",
      "208:\tlearn: 0.3372697\ttotal: 4m 47s\tremaining: 18m 9s\n",
      "209:\tlearn: 0.3358465\ttotal: 4m 49s\tremaining: 18m 8s\n",
      "210:\tlearn: 0.3343916\ttotal: 4m 51s\tremaining: 18m 8s\n",
      "211:\tlearn: 0.3332656\ttotal: 4m 52s\tremaining: 18m 7s\n",
      "212:\tlearn: 0.3322656\ttotal: 4m 53s\tremaining: 18m 5s\n",
      "213:\tlearn: 0.3306830\ttotal: 4m 55s\tremaining: 18m 4s\n",
      "214:\tlearn: 0.3287676\ttotal: 4m 56s\tremaining: 18m 3s\n",
      "215:\tlearn: 0.3272843\ttotal: 4m 57s\tremaining: 18m 1s\n",
      "216:\tlearn: 0.3259157\ttotal: 4m 59s\tremaining: 18m\n",
      "217:\tlearn: 0.3242566\ttotal: 5m\tremaining: 17m 59s\n",
      "218:\tlearn: 0.3228020\ttotal: 5m 2s\tremaining: 17m 57s\n",
      "219:\tlearn: 0.3213139\ttotal: 5m 3s\tremaining: 17m 56s\n",
      "220:\tlearn: 0.3197669\ttotal: 5m 4s\tremaining: 17m 54s\n",
      "221:\tlearn: 0.3186062\ttotal: 5m 6s\tremaining: 17m 53s\n",
      "222:\tlearn: 0.3174127\ttotal: 5m 7s\tremaining: 17m 52s\n",
      "223:\tlearn: 0.3163143\ttotal: 5m 9s\tremaining: 17m 50s\n",
      "224:\tlearn: 0.3152362\ttotal: 5m 10s\tremaining: 17m 49s\n",
      "225:\tlearn: 0.3133727\ttotal: 5m 11s\tremaining: 17m 48s\n",
      "226:\tlearn: 0.3119986\ttotal: 5m 13s\tremaining: 17m 46s\n",
      "227:\tlearn: 0.3106290\ttotal: 5m 15s\tremaining: 17m 47s\n",
      "228:\tlearn: 0.3090428\ttotal: 5m 16s\tremaining: 17m 46s\n",
      "229:\tlearn: 0.3073229\ttotal: 5m 18s\tremaining: 17m 45s\n",
      "230:\tlearn: 0.3064606\ttotal: 5m 19s\tremaining: 17m 44s\n",
      "231:\tlearn: 0.3050754\ttotal: 5m 21s\tremaining: 17m 43s\n",
      "232:\tlearn: 0.3041767\ttotal: 5m 22s\tremaining: 17m 42s\n",
      "233:\tlearn: 0.3022733\ttotal: 5m 24s\tremaining: 17m 42s\n",
      "234:\tlearn: 0.3013105\ttotal: 5m 26s\tremaining: 17m 42s\n",
      "235:\tlearn: 0.2995026\ttotal: 5m 28s\tremaining: 17m 41s\n",
      "236:\tlearn: 0.2975143\ttotal: 5m 29s\tremaining: 17m 41s\n",
      "237:\tlearn: 0.2960150\ttotal: 5m 31s\tremaining: 17m 41s\n",
      "238:\tlearn: 0.2951392\ttotal: 5m 33s\tremaining: 17m 40s\n",
      "239:\tlearn: 0.2931635\ttotal: 5m 35s\tremaining: 17m 40s\n",
      "240:\tlearn: 0.2919329\ttotal: 5m 36s\tremaining: 17m 40s\n",
      "241:\tlearn: 0.2908807\ttotal: 5m 38s\tremaining: 17m 40s\n",
      "242:\tlearn: 0.2898703\ttotal: 5m 40s\tremaining: 17m 39s\n",
      "243:\tlearn: 0.2878767\ttotal: 5m 41s\tremaining: 17m 38s\n",
      "244:\tlearn: 0.2867954\ttotal: 5m 43s\tremaining: 17m 37s\n",
      "245:\tlearn: 0.2847752\ttotal: 5m 44s\tremaining: 17m 35s\n",
      "246:\tlearn: 0.2833642\ttotal: 5m 45s\tremaining: 17m 33s\n",
      "247:\tlearn: 0.2820409\ttotal: 5m 46s\tremaining: 17m 31s\n",
      "248:\tlearn: 0.2802854\ttotal: 5m 47s\tremaining: 17m 29s\n",
      "249:\tlearn: 0.2790199\ttotal: 5m 49s\tremaining: 17m 27s\n",
      "250:\tlearn: 0.2782875\ttotal: 5m 50s\tremaining: 17m 25s\n",
      "251:\tlearn: 0.2777560\ttotal: 5m 51s\tremaining: 17m 23s\n",
      "252:\tlearn: 0.2764434\ttotal: 5m 52s\tremaining: 17m 21s\n",
      "253:\tlearn: 0.2749076\ttotal: 5m 54s\tremaining: 17m 19s\n",
      "254:\tlearn: 0.2735288\ttotal: 5m 55s\tremaining: 17m 17s\n",
      "255:\tlearn: 0.2724517\ttotal: 5m 56s\tremaining: 17m 16s\n",
      "256:\tlearn: 0.2714820\ttotal: 5m 57s\tremaining: 17m 14s\n",
      "257:\tlearn: 0.2701877\ttotal: 5m 59s\tremaining: 17m 12s\n",
      "258:\tlearn: 0.2688584\ttotal: 6m\tremaining: 17m 11s\n",
      "259:\tlearn: 0.2673020\ttotal: 6m 1s\tremaining: 17m 9s\n",
      "260:\tlearn: 0.2665169\ttotal: 6m 3s\tremaining: 17m 8s\n",
      "261:\tlearn: 0.2656106\ttotal: 6m 4s\tremaining: 17m 6s\n",
      "262:\tlearn: 0.2645085\ttotal: 6m 5s\tremaining: 17m 5s\n",
      "263:\tlearn: 0.2635008\ttotal: 6m 7s\tremaining: 17m 3s\n",
      "264:\tlearn: 0.2624009\ttotal: 6m 8s\tremaining: 17m 2s\n",
      "265:\tlearn: 0.2616525\ttotal: 6m 9s\tremaining: 17m\n",
      "266:\tlearn: 0.2610016\ttotal: 6m 11s\tremaining: 16m 59s\n",
      "267:\tlearn: 0.2600704\ttotal: 6m 12s\tremaining: 16m 58s\n",
      "268:\tlearn: 0.2595807\ttotal: 6m 14s\tremaining: 16m 56s\n",
      "269:\tlearn: 0.2578830\ttotal: 6m 15s\tremaining: 16m 55s\n",
      "270:\tlearn: 0.2567563\ttotal: 6m 17s\tremaining: 16m 54s\n",
      "271:\tlearn: 0.2553892\ttotal: 6m 18s\tremaining: 16m 54s\n",
      "272:\tlearn: 0.2540781\ttotal: 6m 20s\tremaining: 16m 53s\n",
      "273:\tlearn: 0.2524992\ttotal: 6m 22s\tremaining: 16m 52s\n",
      "274:\tlearn: 0.2514073\ttotal: 6m 23s\tremaining: 16m 51s\n",
      "275:\tlearn: 0.2503858\ttotal: 6m 25s\tremaining: 16m 50s\n",
      "276:\tlearn: 0.2492275\ttotal: 6m 26s\tremaining: 16m 49s\n",
      "277:\tlearn: 0.2476576\ttotal: 6m 28s\tremaining: 16m 48s\n",
      "278:\tlearn: 0.2469869\ttotal: 6m 29s\tremaining: 16m 47s\n",
      "279:\tlearn: 0.2458089\ttotal: 6m 31s\tremaining: 16m 45s\n",
      "280:\tlearn: 0.2446025\ttotal: 6m 32s\tremaining: 16m 44s\n",
      "281:\tlearn: 0.2437074\ttotal: 6m 33s\tremaining: 16m 43s\n",
      "282:\tlearn: 0.2424145\ttotal: 6m 35s\tremaining: 16m 41s\n",
      "283:\tlearn: 0.2415788\ttotal: 6m 36s\tremaining: 16m 40s\n",
      "284:\tlearn: 0.2404623\ttotal: 6m 38s\tremaining: 16m 39s\n",
      "285:\tlearn: 0.2394009\ttotal: 6m 39s\tremaining: 16m 38s\n",
      "286:\tlearn: 0.2381643\ttotal: 6m 41s\tremaining: 16m 37s\n",
      "287:\tlearn: 0.2367751\ttotal: 6m 42s\tremaining: 16m 36s\n",
      "288:\tlearn: 0.2359728\ttotal: 6m 44s\tremaining: 16m 35s\n",
      "289:\tlearn: 0.2347670\ttotal: 6m 45s\tremaining: 16m 33s\n",
      "290:\tlearn: 0.2334672\ttotal: 6m 47s\tremaining: 16m 31s\n",
      "291:\tlearn: 0.2325474\ttotal: 6m 48s\tremaining: 16m 30s\n",
      "292:\tlearn: 0.2316216\ttotal: 6m 49s\tremaining: 16m 28s\n",
      "293:\tlearn: 0.2305963\ttotal: 6m 51s\tremaining: 16m 27s\n",
      "294:\tlearn: 0.2295163\ttotal: 6m 52s\tremaining: 16m 26s\n",
      "295:\tlearn: 0.2289389\ttotal: 6m 54s\tremaining: 16m 25s\n",
      "296:\tlearn: 0.2281001\ttotal: 6m 55s\tremaining: 16m 23s\n",
      "297:\tlearn: 0.2271726\ttotal: 6m 57s\tremaining: 16m 23s\n",
      "298:\tlearn: 0.2261986\ttotal: 6m 58s\tremaining: 16m 22s\n",
      "299:\tlearn: 0.2256156\ttotal: 7m\tremaining: 16m 20s\n",
      "300:\tlearn: 0.2247265\ttotal: 7m 1s\tremaining: 16m 19s\n",
      "301:\tlearn: 0.2236649\ttotal: 7m 3s\tremaining: 16m 17s\n",
      "302:\tlearn: 0.2230068\ttotal: 7m 4s\tremaining: 16m 16s\n",
      "303:\tlearn: 0.2214971\ttotal: 7m 5s\tremaining: 16m 14s\n",
      "304:\tlearn: 0.2204225\ttotal: 7m 7s\tremaining: 16m 13s\n",
      "305:\tlearn: 0.2198289\ttotal: 7m 8s\tremaining: 16m 11s\n",
      "306:\tlearn: 0.2192368\ttotal: 7m 9s\tremaining: 16m 9s\n",
      "307:\tlearn: 0.2187117\ttotal: 7m 10s\tremaining: 16m 8s\n",
      "308:\tlearn: 0.2177857\ttotal: 7m 12s\tremaining: 16m 6s\n",
      "309:\tlearn: 0.2168874\ttotal: 7m 13s\tremaining: 16m 4s\n",
      "310:\tlearn: 0.2160135\ttotal: 7m 14s\tremaining: 16m 3s\n",
      "311:\tlearn: 0.2152475\ttotal: 7m 16s\tremaining: 16m 1s\n",
      "312:\tlearn: 0.2147445\ttotal: 7m 17s\tremaining: 16m\n",
      "313:\tlearn: 0.2138619\ttotal: 7m 18s\tremaining: 15m 59s\n",
      "314:\tlearn: 0.2131129\ttotal: 7m 20s\tremaining: 15m 57s\n",
      "315:\tlearn: 0.2124691\ttotal: 7m 21s\tremaining: 15m 56s\n",
      "316:\tlearn: 0.2118653\ttotal: 7m 23s\tremaining: 15m 54s\n",
      "317:\tlearn: 0.2111715\ttotal: 7m 24s\tremaining: 15m 52s\n",
      "318:\tlearn: 0.2102830\ttotal: 7m 25s\tremaining: 15m 51s\n",
      "319:\tlearn: 0.2090840\ttotal: 7m 26s\tremaining: 15m 49s\n",
      "320:\tlearn: 0.2085864\ttotal: 7m 28s\tremaining: 15m 48s\n",
      "321:\tlearn: 0.2080617\ttotal: 7m 29s\tremaining: 15m 46s\n",
      "322:\tlearn: 0.2069624\ttotal: 7m 31s\tremaining: 15m 45s\n",
      "323:\tlearn: 0.2058200\ttotal: 7m 32s\tremaining: 15m 44s\n",
      "324:\tlearn: 0.2047295\ttotal: 7m 34s\tremaining: 15m 43s\n",
      "325:\tlearn: 0.2040686\ttotal: 7m 35s\tremaining: 15m 42s\n",
      "326:\tlearn: 0.2030812\ttotal: 7m 37s\tremaining: 15m 41s\n",
      "327:\tlearn: 0.2024889\ttotal: 7m 38s\tremaining: 15m 40s\n",
      "328:\tlearn: 0.2015705\ttotal: 7m 40s\tremaining: 15m 38s\n",
      "329:\tlearn: 0.2011018\ttotal: 7m 41s\tremaining: 15m 37s\n",
      "330:\tlearn: 0.2002532\ttotal: 7m 43s\tremaining: 15m 36s\n",
      "331:\tlearn: 0.1989907\ttotal: 7m 44s\tremaining: 15m 35s\n",
      "332:\tlearn: 0.1981124\ttotal: 7m 46s\tremaining: 15m 34s\n",
      "333:\tlearn: 0.1972745\ttotal: 7m 47s\tremaining: 15m 32s\n",
      "334:\tlearn: 0.1966123\ttotal: 7m 49s\tremaining: 15m 31s\n",
      "335:\tlearn: 0.1956990\ttotal: 7m 50s\tremaining: 15m 29s\n",
      "336:\tlearn: 0.1950942\ttotal: 7m 51s\tremaining: 15m 28s\n",
      "337:\tlearn: 0.1944113\ttotal: 7m 53s\tremaining: 15m 27s\n",
      "338:\tlearn: 0.1932704\ttotal: 7m 54s\tremaining: 15m 25s\n",
      "339:\tlearn: 0.1924260\ttotal: 7m 55s\tremaining: 15m 23s\n",
      "340:\tlearn: 0.1918790\ttotal: 7m 57s\tremaining: 15m 22s\n",
      "341:\tlearn: 0.1910508\ttotal: 7m 58s\tremaining: 15m 20s\n",
      "342:\tlearn: 0.1902663\ttotal: 7m 59s\tremaining: 15m 19s\n",
      "343:\tlearn: 0.1896016\ttotal: 8m 1s\tremaining: 15m 17s\n",
      "344:\tlearn: 0.1885832\ttotal: 8m 2s\tremaining: 15m 16s\n",
      "345:\tlearn: 0.1879680\ttotal: 8m 4s\tremaining: 15m 15s\n",
      "346:\tlearn: 0.1875226\ttotal: 8m 5s\tremaining: 15m 13s\n",
      "347:\tlearn: 0.1866950\ttotal: 8m 6s\tremaining: 15m 12s\n",
      "348:\tlearn: 0.1857185\ttotal: 8m 8s\tremaining: 15m 10s\n",
      "349:\tlearn: 0.1851300\ttotal: 8m 9s\tremaining: 15m 9s\n",
      "350:\tlearn: 0.1844462\ttotal: 8m 11s\tremaining: 15m 7s\n",
      "351:\tlearn: 0.1838500\ttotal: 8m 12s\tremaining: 15m 6s\n",
      "352:\tlearn: 0.1830519\ttotal: 8m 13s\tremaining: 15m 5s\n",
      "353:\tlearn: 0.1823615\ttotal: 8m 15s\tremaining: 15m 3s\n",
      "354:\tlearn: 0.1816992\ttotal: 8m 16s\tremaining: 15m 2s\n",
      "355:\tlearn: 0.1808897\ttotal: 8m 17s\tremaining: 15m\n",
      "356:\tlearn: 0.1804120\ttotal: 8m 19s\tremaining: 14m 59s\n",
      "357:\tlearn: 0.1795245\ttotal: 8m 20s\tremaining: 14m 57s\n",
      "358:\tlearn: 0.1790752\ttotal: 8m 21s\tremaining: 14m 55s\n",
      "359:\tlearn: 0.1783618\ttotal: 8m 23s\tremaining: 14m 54s\n",
      "360:\tlearn: 0.1779397\ttotal: 8m 24s\tremaining: 14m 52s\n",
      "361:\tlearn: 0.1772218\ttotal: 8m 25s\tremaining: 14m 51s\n",
      "362:\tlearn: 0.1766191\ttotal: 8m 26s\tremaining: 14m 49s\n",
      "363:\tlearn: 0.1757265\ttotal: 8m 28s\tremaining: 14m 47s\n",
      "364:\tlearn: 0.1751345\ttotal: 8m 29s\tremaining: 14m 46s\n",
      "365:\tlearn: 0.1746781\ttotal: 8m 30s\tremaining: 14m 44s\n",
      "366:\tlearn: 0.1740253\ttotal: 8m 31s\tremaining: 14m 42s\n",
      "367:\tlearn: 0.1733373\ttotal: 8m 33s\tremaining: 14m 41s\n",
      "368:\tlearn: 0.1726789\ttotal: 8m 34s\tremaining: 14m 39s\n",
      "369:\tlearn: 0.1715936\ttotal: 8m 35s\tremaining: 14m 38s\n",
      "370:\tlearn: 0.1710066\ttotal: 8m 36s\tremaining: 14m 36s\n",
      "371:\tlearn: 0.1705194\ttotal: 8m 38s\tremaining: 14m 34s\n",
      "372:\tlearn: 0.1697655\ttotal: 8m 39s\tremaining: 14m 33s\n",
      "373:\tlearn: 0.1689619\ttotal: 8m 40s\tremaining: 14m 31s\n",
      "374:\tlearn: 0.1683297\ttotal: 8m 42s\tremaining: 14m 30s\n",
      "375:\tlearn: 0.1680065\ttotal: 8m 43s\tremaining: 14m 28s\n",
      "376:\tlearn: 0.1674544\ttotal: 8m 44s\tremaining: 14m 27s\n",
      "377:\tlearn: 0.1670117\ttotal: 8m 46s\tremaining: 14m 26s\n",
      "378:\tlearn: 0.1661521\ttotal: 8m 48s\tremaining: 14m 25s\n",
      "379:\tlearn: 0.1653104\ttotal: 8m 49s\tremaining: 14m 24s\n",
      "380:\tlearn: 0.1645280\ttotal: 8m 51s\tremaining: 14m 23s\n",
      "381:\tlearn: 0.1636917\ttotal: 8m 52s\tremaining: 14m 22s\n",
      "382:\tlearn: 0.1629612\ttotal: 8m 54s\tremaining: 14m 21s\n",
      "383:\tlearn: 0.1625269\ttotal: 8m 56s\tremaining: 14m 19s\n",
      "384:\tlearn: 0.1618376\ttotal: 8m 57s\tremaining: 14m 18s\n",
      "385:\tlearn: 0.1612286\ttotal: 8m 59s\tremaining: 14m 17s\n",
      "386:\tlearn: 0.1608904\ttotal: 9m\tremaining: 14m 16s\n",
      "387:\tlearn: 0.1601815\ttotal: 9m 2s\tremaining: 14m 15s\n",
      "388:\tlearn: 0.1595493\ttotal: 9m 3s\tremaining: 14m 14s\n",
      "389:\tlearn: 0.1590479\ttotal: 9m 5s\tremaining: 14m 13s\n",
      "390:\tlearn: 0.1586719\ttotal: 9m 6s\tremaining: 14m 11s\n",
      "391:\tlearn: 0.1580881\ttotal: 9m 8s\tremaining: 14m 10s\n",
      "392:\tlearn: 0.1574766\ttotal: 9m 9s\tremaining: 14m 9s\n",
      "393:\tlearn: 0.1569093\ttotal: 9m 11s\tremaining: 14m 8s\n",
      "394:\tlearn: 0.1561689\ttotal: 9m 13s\tremaining: 14m 7s\n",
      "395:\tlearn: 0.1556461\ttotal: 9m 14s\tremaining: 14m 6s\n",
      "396:\tlearn: 0.1550315\ttotal: 9m 16s\tremaining: 14m 5s\n",
      "397:\tlearn: 0.1544024\ttotal: 9m 18s\tremaining: 14m 4s\n",
      "398:\tlearn: 0.1538709\ttotal: 9m 19s\tremaining: 14m 2s\n",
      "399:\tlearn: 0.1532806\ttotal: 9m 20s\tremaining: 14m 1s\n",
      "400:\tlearn: 0.1529846\ttotal: 9m 22s\tremaining: 13m 59s\n",
      "401:\tlearn: 0.1523115\ttotal: 9m 23s\tremaining: 13m 58s\n",
      "402:\tlearn: 0.1517200\ttotal: 9m 25s\tremaining: 13m 57s\n",
      "403:\tlearn: 0.1514040\ttotal: 9m 26s\tremaining: 13m 55s\n",
      "404:\tlearn: 0.1510284\ttotal: 9m 27s\tremaining: 13m 54s\n",
      "405:\tlearn: 0.1505761\ttotal: 9m 29s\tremaining: 13m 52s\n",
      "406:\tlearn: 0.1500639\ttotal: 9m 30s\tremaining: 13m 51s\n",
      "407:\tlearn: 0.1495648\ttotal: 9m 31s\tremaining: 13m 49s\n",
      "408:\tlearn: 0.1491319\ttotal: 9m 33s\tremaining: 13m 48s\n",
      "409:\tlearn: 0.1486806\ttotal: 9m 34s\tremaining: 13m 46s\n",
      "410:\tlearn: 0.1482140\ttotal: 9m 35s\tremaining: 13m 44s\n",
      "411:\tlearn: 0.1476553\ttotal: 9m 36s\tremaining: 13m 42s\n",
      "412:\tlearn: 0.1470194\ttotal: 9m 37s\tremaining: 13m 41s\n",
      "413:\tlearn: 0.1464237\ttotal: 9m 39s\tremaining: 13m 39s\n",
      "414:\tlearn: 0.1459133\ttotal: 9m 40s\tremaining: 13m 38s\n",
      "415:\tlearn: 0.1456095\ttotal: 9m 41s\tremaining: 13m 36s\n",
      "416:\tlearn: 0.1451555\ttotal: 9m 42s\tremaining: 13m 34s\n",
      "417:\tlearn: 0.1446011\ttotal: 9m 44s\tremaining: 13m 33s\n",
      "418:\tlearn: 0.1442047\ttotal: 9m 45s\tremaining: 13m 31s\n",
      "419:\tlearn: 0.1436231\ttotal: 9m 46s\tremaining: 13m 30s\n",
      "420:\tlearn: 0.1432394\ttotal: 9m 47s\tremaining: 13m 28s\n",
      "421:\tlearn: 0.1426660\ttotal: 9m 49s\tremaining: 13m 26s\n",
      "422:\tlearn: 0.1422684\ttotal: 9m 50s\tremaining: 13m 25s\n",
      "423:\tlearn: 0.1417584\ttotal: 9m 51s\tremaining: 13m 23s\n",
      "424:\tlearn: 0.1412646\ttotal: 9m 52s\tremaining: 13m 21s\n",
      "425:\tlearn: 0.1407677\ttotal: 9m 53s\tremaining: 13m 19s\n",
      "426:\tlearn: 0.1404585\ttotal: 9m 54s\tremaining: 13m 18s\n",
      "427:\tlearn: 0.1399760\ttotal: 9m 56s\tremaining: 13m 16s\n",
      "428:\tlearn: 0.1393382\ttotal: 9m 57s\tremaining: 13m 14s\n",
      "429:\tlearn: 0.1388236\ttotal: 9m 58s\tremaining: 13m 13s\n",
      "430:\tlearn: 0.1382105\ttotal: 9m 59s\tremaining: 13m 11s\n",
      "431:\tlearn: 0.1378386\ttotal: 10m 1s\tremaining: 13m 10s\n",
      "432:\tlearn: 0.1373342\ttotal: 10m 2s\tremaining: 13m 8s\n",
      "433:\tlearn: 0.1366760\ttotal: 10m 3s\tremaining: 13m 7s\n",
      "434:\tlearn: 0.1360735\ttotal: 10m 4s\tremaining: 13m 5s\n",
      "435:\tlearn: 0.1356921\ttotal: 10m 6s\tremaining: 13m 4s\n",
      "436:\tlearn: 0.1351686\ttotal: 10m 7s\tremaining: 13m 2s\n",
      "437:\tlearn: 0.1346828\ttotal: 10m 8s\tremaining: 13m 1s\n",
      "438:\tlearn: 0.1344306\ttotal: 10m 9s\tremaining: 12m 59s\n",
      "439:\tlearn: 0.1338637\ttotal: 10m 11s\tremaining: 12m 57s\n",
      "440:\tlearn: 0.1334223\ttotal: 10m 12s\tremaining: 12m 56s\n",
      "441:\tlearn: 0.1330685\ttotal: 10m 13s\tremaining: 12m 54s\n",
      "442:\tlearn: 0.1326159\ttotal: 10m 15s\tremaining: 12m 53s\n",
      "443:\tlearn: 0.1321130\ttotal: 10m 16s\tremaining: 12m 52s\n",
      "444:\tlearn: 0.1316159\ttotal: 10m 18s\tremaining: 12m 50s\n",
      "445:\tlearn: 0.1311057\ttotal: 10m 19s\tremaining: 12m 49s\n",
      "446:\tlearn: 0.1308300\ttotal: 10m 20s\tremaining: 12m 48s\n",
      "447:\tlearn: 0.1304046\ttotal: 10m 22s\tremaining: 12m 46s\n",
      "448:\tlearn: 0.1301389\ttotal: 10m 23s\tremaining: 12m 45s\n",
      "449:\tlearn: 0.1296467\ttotal: 10m 24s\tremaining: 12m 43s\n",
      "450:\tlearn: 0.1291870\ttotal: 10m 26s\tremaining: 12m 42s\n",
      "451:\tlearn: 0.1286725\ttotal: 10m 27s\tremaining: 12m 40s\n",
      "452:\tlearn: 0.1283005\ttotal: 10m 29s\tremaining: 12m 39s\n",
      "453:\tlearn: 0.1280269\ttotal: 10m 30s\tremaining: 12m 38s\n",
      "454:\tlearn: 0.1275088\ttotal: 10m 31s\tremaining: 12m 36s\n",
      "455:\tlearn: 0.1269621\ttotal: 10m 33s\tremaining: 12m 35s\n",
      "456:\tlearn: 0.1264056\ttotal: 10m 34s\tremaining: 12m 34s\n",
      "457:\tlearn: 0.1260073\ttotal: 10m 36s\tremaining: 12m 32s\n",
      "458:\tlearn: 0.1255963\ttotal: 10m 37s\tremaining: 12m 31s\n",
      "459:\tlearn: 0.1251807\ttotal: 10m 39s\tremaining: 12m 30s\n",
      "460:\tlearn: 0.1246906\ttotal: 10m 40s\tremaining: 12m 28s\n",
      "461:\tlearn: 0.1242543\ttotal: 10m 41s\tremaining: 12m 27s\n",
      "462:\tlearn: 0.1238536\ttotal: 10m 43s\tremaining: 12m 26s\n",
      "463:\tlearn: 0.1236626\ttotal: 10m 44s\tremaining: 12m 24s\n",
      "464:\tlearn: 0.1232715\ttotal: 10m 46s\tremaining: 12m 23s\n",
      "465:\tlearn: 0.1228946\ttotal: 10m 47s\tremaining: 12m 22s\n",
      "466:\tlearn: 0.1224606\ttotal: 10m 48s\tremaining: 12m 20s\n",
      "467:\tlearn: 0.1221773\ttotal: 10m 50s\tremaining: 12m 19s\n",
      "468:\tlearn: 0.1217117\ttotal: 10m 51s\tremaining: 12m 17s\n",
      "469:\tlearn: 0.1212951\ttotal: 10m 53s\tremaining: 12m 16s\n",
      "470:\tlearn: 0.1207793\ttotal: 10m 54s\tremaining: 12m 15s\n",
      "471:\tlearn: 0.1203974\ttotal: 10m 55s\tremaining: 12m 13s\n",
      "472:\tlearn: 0.1200219\ttotal: 10m 57s\tremaining: 12m 12s\n",
      "473:\tlearn: 0.1196854\ttotal: 10m 58s\tremaining: 12m 10s\n",
      "474:\tlearn: 0.1192614\ttotal: 10m 59s\tremaining: 12m 9s\n",
      "475:\tlearn: 0.1187688\ttotal: 11m 1s\tremaining: 12m 7s\n",
      "476:\tlearn: 0.1184842\ttotal: 11m 2s\tremaining: 12m 6s\n",
      "477:\tlearn: 0.1180570\ttotal: 11m 3s\tremaining: 12m 4s\n",
      "478:\tlearn: 0.1175977\ttotal: 11m 5s\tremaining: 12m 3s\n",
      "479:\tlearn: 0.1173350\ttotal: 11m 6s\tremaining: 12m 1s\n",
      "480:\tlearn: 0.1169233\ttotal: 11m 7s\tremaining: 12m\n",
      "481:\tlearn: 0.1165893\ttotal: 11m 8s\tremaining: 11m 58s\n",
      "482:\tlearn: 0.1161907\ttotal: 11m 10s\tremaining: 11m 57s\n",
      "483:\tlearn: 0.1158990\ttotal: 11m 11s\tremaining: 11m 55s\n",
      "484:\tlearn: 0.1156492\ttotal: 11m 12s\tremaining: 11m 54s\n",
      "485:\tlearn: 0.1152086\ttotal: 11m 14s\tremaining: 11m 52s\n",
      "486:\tlearn: 0.1147927\ttotal: 11m 15s\tremaining: 11m 51s\n",
      "487:\tlearn: 0.1142676\ttotal: 11m 16s\tremaining: 11m 50s\n",
      "488:\tlearn: 0.1138280\ttotal: 11m 18s\tremaining: 11m 48s\n",
      "489:\tlearn: 0.1134730\ttotal: 11m 19s\tremaining: 11m 47s\n",
      "490:\tlearn: 0.1130914\ttotal: 11m 20s\tremaining: 11m 45s\n",
      "491:\tlearn: 0.1127264\ttotal: 11m 22s\tremaining: 11m 44s\n",
      "492:\tlearn: 0.1124906\ttotal: 11m 23s\tremaining: 11m 42s\n",
      "493:\tlearn: 0.1120536\ttotal: 11m 24s\tremaining: 11m 41s\n",
      "494:\tlearn: 0.1118268\ttotal: 11m 26s\tremaining: 11m 39s\n",
      "495:\tlearn: 0.1116303\ttotal: 11m 27s\tremaining: 11m 38s\n",
      "496:\tlearn: 0.1112099\ttotal: 11m 28s\tremaining: 11m 37s\n",
      "497:\tlearn: 0.1109152\ttotal: 11m 30s\tremaining: 11m 35s\n",
      "498:\tlearn: 0.1106024\ttotal: 11m 31s\tremaining: 11m 33s\n",
      "499:\tlearn: 0.1102501\ttotal: 11m 32s\tremaining: 11m 32s\n",
      "500:\tlearn: 0.1099930\ttotal: 11m 33s\tremaining: 11m 30s\n",
      "501:\tlearn: 0.1096407\ttotal: 11m 35s\tremaining: 11m 29s\n",
      "502:\tlearn: 0.1092929\ttotal: 11m 36s\tremaining: 11m 28s\n",
      "503:\tlearn: 0.1090524\ttotal: 11m 38s\tremaining: 11m 26s\n",
      "504:\tlearn: 0.1087381\ttotal: 11m 39s\tremaining: 11m 25s\n",
      "505:\tlearn: 0.1082524\ttotal: 11m 40s\tremaining: 11m 24s\n",
      "506:\tlearn: 0.1079708\ttotal: 11m 42s\tremaining: 11m 22s\n",
      "507:\tlearn: 0.1077412\ttotal: 11m 43s\tremaining: 11m 21s\n",
      "508:\tlearn: 0.1074526\ttotal: 11m 44s\tremaining: 11m 20s\n",
      "509:\tlearn: 0.1071997\ttotal: 11m 46s\tremaining: 11m 18s\n",
      "510:\tlearn: 0.1068922\ttotal: 11m 47s\tremaining: 11m 17s\n",
      "511:\tlearn: 0.1065111\ttotal: 11m 49s\tremaining: 11m 15s\n",
      "512:\tlearn: 0.1061913\ttotal: 11m 50s\tremaining: 11m 14s\n",
      "513:\tlearn: 0.1058904\ttotal: 11m 51s\tremaining: 11m 13s\n",
      "514:\tlearn: 0.1056049\ttotal: 11m 53s\tremaining: 11m 11s\n",
      "515:\tlearn: 0.1053426\ttotal: 11m 54s\tremaining: 11m 10s\n",
      "516:\tlearn: 0.1049495\ttotal: 11m 56s\tremaining: 11m 8s\n",
      "517:\tlearn: 0.1047376\ttotal: 11m 57s\tremaining: 11m 7s\n",
      "518:\tlearn: 0.1043114\ttotal: 11m 58s\tremaining: 11m 6s\n",
      "519:\tlearn: 0.1039126\ttotal: 12m\tremaining: 11m 4s\n",
      "520:\tlearn: 0.1036633\ttotal: 12m 1s\tremaining: 11m 3s\n",
      "521:\tlearn: 0.1033543\ttotal: 12m 3s\tremaining: 11m 2s\n",
      "522:\tlearn: 0.1029736\ttotal: 12m 4s\tremaining: 11m\n",
      "523:\tlearn: 0.1027816\ttotal: 12m 5s\tremaining: 10m 59s\n",
      "524:\tlearn: 0.1024598\ttotal: 12m 7s\tremaining: 10m 57s\n",
      "525:\tlearn: 0.1021176\ttotal: 12m 8s\tremaining: 10m 56s\n",
      "526:\tlearn: 0.1018104\ttotal: 12m 9s\tremaining: 10m 55s\n",
      "527:\tlearn: 0.1015910\ttotal: 12m 11s\tremaining: 10m 53s\n",
      "528:\tlearn: 0.1013843\ttotal: 12m 12s\tremaining: 10m 52s\n",
      "529:\tlearn: 0.1010585\ttotal: 12m 13s\tremaining: 10m 50s\n",
      "530:\tlearn: 0.1007711\ttotal: 12m 15s\tremaining: 10m 49s\n",
      "531:\tlearn: 0.1004904\ttotal: 12m 16s\tremaining: 10m 48s\n",
      "532:\tlearn: 0.1000653\ttotal: 12m 18s\tremaining: 10m 46s\n",
      "533:\tlearn: 0.0997550\ttotal: 12m 19s\tremaining: 10m 45s\n",
      "534:\tlearn: 0.0994295\ttotal: 12m 20s\tremaining: 10m 43s\n",
      "535:\tlearn: 0.0991212\ttotal: 12m 22s\tremaining: 10m 42s\n",
      "536:\tlearn: 0.0987433\ttotal: 12m 23s\tremaining: 10m 41s\n",
      "537:\tlearn: 0.0984364\ttotal: 12m 24s\tremaining: 10m 39s\n",
      "538:\tlearn: 0.0981846\ttotal: 12m 26s\tremaining: 10m 38s\n",
      "539:\tlearn: 0.0980013\ttotal: 12m 27s\tremaining: 10m 36s\n",
      "540:\tlearn: 0.0977369\ttotal: 12m 29s\tremaining: 10m 35s\n",
      "541:\tlearn: 0.0974706\ttotal: 12m 30s\tremaining: 10m 34s\n",
      "542:\tlearn: 0.0971865\ttotal: 12m 31s\tremaining: 10m 32s\n",
      "543:\tlearn: 0.0968130\ttotal: 12m 33s\tremaining: 10m 31s\n",
      "544:\tlearn: 0.0965674\ttotal: 12m 34s\tremaining: 10m 29s\n",
      "545:\tlearn: 0.0962715\ttotal: 12m 35s\tremaining: 10m 28s\n",
      "546:\tlearn: 0.0960553\ttotal: 12m 37s\tremaining: 10m 27s\n",
      "547:\tlearn: 0.0956797\ttotal: 12m 38s\tremaining: 10m 25s\n",
      "548:\tlearn: 0.0953826\ttotal: 12m 40s\tremaining: 10m 24s\n",
      "549:\tlearn: 0.0951248\ttotal: 12m 41s\tremaining: 10m 23s\n",
      "550:\tlearn: 0.0948598\ttotal: 12m 42s\tremaining: 10m 21s\n",
      "551:\tlearn: 0.0946875\ttotal: 12m 44s\tremaining: 10m 20s\n",
      "552:\tlearn: 0.0943760\ttotal: 12m 45s\tremaining: 10m 18s\n",
      "553:\tlearn: 0.0941900\ttotal: 12m 47s\tremaining: 10m 17s\n",
      "554:\tlearn: 0.0939992\ttotal: 12m 48s\tremaining: 10m 16s\n",
      "555:\tlearn: 0.0937863\ttotal: 12m 49s\tremaining: 10m 14s\n",
      "556:\tlearn: 0.0935044\ttotal: 12m 51s\tremaining: 10m 13s\n",
      "557:\tlearn: 0.0932430\ttotal: 12m 52s\tremaining: 10m 11s\n",
      "558:\tlearn: 0.0929116\ttotal: 12m 53s\tremaining: 10m 10s\n",
      "559:\tlearn: 0.0927277\ttotal: 12m 55s\tremaining: 10m 9s\n",
      "560:\tlearn: 0.0924037\ttotal: 12m 56s\tremaining: 10m 7s\n",
      "561:\tlearn: 0.0921652\ttotal: 12m 58s\tremaining: 10m 6s\n",
      "562:\tlearn: 0.0920054\ttotal: 12m 59s\tremaining: 10m 4s\n",
      "563:\tlearn: 0.0918397\ttotal: 13m\tremaining: 10m 3s\n",
      "564:\tlearn: 0.0915756\ttotal: 13m 2s\tremaining: 10m 2s\n",
      "565:\tlearn: 0.0913408\ttotal: 13m 3s\tremaining: 10m\n",
      "566:\tlearn: 0.0910020\ttotal: 13m 4s\tremaining: 9m 59s\n",
      "567:\tlearn: 0.0907794\ttotal: 13m 6s\tremaining: 9m 57s\n",
      "568:\tlearn: 0.0906761\ttotal: 13m 7s\tremaining: 9m 56s\n",
      "569:\tlearn: 0.0904909\ttotal: 13m 8s\tremaining: 9m 55s\n",
      "570:\tlearn: 0.0901615\ttotal: 13m 10s\tremaining: 9m 53s\n",
      "571:\tlearn: 0.0898815\ttotal: 13m 11s\tremaining: 9m 52s\n",
      "572:\tlearn: 0.0896743\ttotal: 13m 13s\tremaining: 9m 51s\n",
      "573:\tlearn: 0.0894716\ttotal: 13m 14s\tremaining: 9m 49s\n",
      "574:\tlearn: 0.0892534\ttotal: 13m 15s\tremaining: 9m 48s\n",
      "575:\tlearn: 0.0889789\ttotal: 13m 17s\tremaining: 9m 46s\n",
      "576:\tlearn: 0.0887663\ttotal: 13m 18s\tremaining: 9m 45s\n",
      "577:\tlearn: 0.0886084\ttotal: 13m 19s\tremaining: 9m 43s\n",
      "578:\tlearn: 0.0884260\ttotal: 13m 21s\tremaining: 9m 42s\n",
      "579:\tlearn: 0.0881092\ttotal: 13m 22s\tremaining: 9m 41s\n",
      "580:\tlearn: 0.0878581\ttotal: 13m 24s\tremaining: 9m 39s\n",
      "581:\tlearn: 0.0877350\ttotal: 13m 25s\tremaining: 9m 38s\n",
      "582:\tlearn: 0.0874627\ttotal: 13m 26s\tremaining: 9m 37s\n",
      "583:\tlearn: 0.0873388\ttotal: 13m 28s\tremaining: 9m 35s\n",
      "584:\tlearn: 0.0870483\ttotal: 13m 29s\tremaining: 9m 34s\n",
      "585:\tlearn: 0.0868582\ttotal: 13m 31s\tremaining: 9m 32s\n",
      "586:\tlearn: 0.0866226\ttotal: 13m 32s\tremaining: 9m 31s\n",
      "587:\tlearn: 0.0864167\ttotal: 13m 33s\tremaining: 9m 30s\n",
      "588:\tlearn: 0.0862485\ttotal: 13m 35s\tremaining: 9m 28s\n",
      "589:\tlearn: 0.0860169\ttotal: 13m 36s\tremaining: 9m 27s\n",
      "590:\tlearn: 0.0856646\ttotal: 13m 38s\tremaining: 9m 26s\n",
      "591:\tlearn: 0.0854466\ttotal: 13m 39s\tremaining: 9m 24s\n",
      "592:\tlearn: 0.0851794\ttotal: 13m 41s\tremaining: 9m 23s\n",
      "593:\tlearn: 0.0848472\ttotal: 13m 42s\tremaining: 9m 22s\n",
      "594:\tlearn: 0.0846395\ttotal: 13m 44s\tremaining: 9m 20s\n",
      "595:\tlearn: 0.0844381\ttotal: 13m 45s\tremaining: 9m 19s\n",
      "596:\tlearn: 0.0842654\ttotal: 13m 46s\tremaining: 9m 18s\n",
      "597:\tlearn: 0.0840233\ttotal: 13m 48s\tremaining: 9m 16s\n",
      "598:\tlearn: 0.0837650\ttotal: 13m 49s\tremaining: 9m 15s\n",
      "599:\tlearn: 0.0835269\ttotal: 13m 51s\tremaining: 9m 14s\n",
      "600:\tlearn: 0.0833651\ttotal: 13m 52s\tremaining: 9m 12s\n",
      "601:\tlearn: 0.0831343\ttotal: 13m 53s\tremaining: 9m 11s\n",
      "602:\tlearn: 0.0829545\ttotal: 13m 55s\tremaining: 9m 9s\n",
      "603:\tlearn: 0.0827391\ttotal: 13m 56s\tremaining: 9m 8s\n",
      "604:\tlearn: 0.0824959\ttotal: 13m 57s\tremaining: 9m 7s\n",
      "605:\tlearn: 0.0823240\ttotal: 13m 59s\tremaining: 9m 5s\n",
      "606:\tlearn: 0.0821694\ttotal: 14m\tremaining: 9m 4s\n",
      "607:\tlearn: 0.0819710\ttotal: 14m 1s\tremaining: 9m 2s\n",
      "608:\tlearn: 0.0817421\ttotal: 14m 2s\tremaining: 9m 1s\n",
      "609:\tlearn: 0.0815848\ttotal: 14m 4s\tremaining: 8m 59s\n",
      "610:\tlearn: 0.0813263\ttotal: 14m 5s\tremaining: 8m 58s\n",
      "611:\tlearn: 0.0812410\ttotal: 14m 6s\tremaining: 8m 56s\n",
      "612:\tlearn: 0.0810567\ttotal: 14m 8s\tremaining: 8m 55s\n",
      "613:\tlearn: 0.0808555\ttotal: 14m 9s\tremaining: 8m 53s\n",
      "614:\tlearn: 0.0806684\ttotal: 14m 10s\tremaining: 8m 52s\n",
      "615:\tlearn: 0.0805206\ttotal: 14m 11s\tremaining: 8m 51s\n",
      "616:\tlearn: 0.0803395\ttotal: 14m 13s\tremaining: 8m 49s\n",
      "617:\tlearn: 0.0800670\ttotal: 14m 14s\tremaining: 8m 48s\n",
      "618:\tlearn: 0.0798517\ttotal: 14m 15s\tremaining: 8m 46s\n",
      "619:\tlearn: 0.0796466\ttotal: 14m 16s\tremaining: 8m 45s\n",
      "620:\tlearn: 0.0794639\ttotal: 14m 18s\tremaining: 8m 43s\n",
      "621:\tlearn: 0.0792582\ttotal: 14m 19s\tremaining: 8m 42s\n",
      "622:\tlearn: 0.0790466\ttotal: 14m 20s\tremaining: 8m 40s\n",
      "623:\tlearn: 0.0786506\ttotal: 14m 22s\tremaining: 8m 39s\n",
      "624:\tlearn: 0.0784557\ttotal: 14m 23s\tremaining: 8m 37s\n",
      "625:\tlearn: 0.0782681\ttotal: 14m 24s\tremaining: 8m 36s\n",
      "626:\tlearn: 0.0780518\ttotal: 14m 25s\tremaining: 8m 35s\n",
      "627:\tlearn: 0.0779054\ttotal: 14m 27s\tremaining: 8m 33s\n",
      "628:\tlearn: 0.0777327\ttotal: 14m 28s\tremaining: 8m 32s\n",
      "629:\tlearn: 0.0775418\ttotal: 14m 29s\tremaining: 8m 30s\n",
      "630:\tlearn: 0.0774040\ttotal: 14m 31s\tremaining: 8m 29s\n",
      "631:\tlearn: 0.0771943\ttotal: 14m 32s\tremaining: 8m 27s\n",
      "632:\tlearn: 0.0770581\ttotal: 14m 33s\tremaining: 8m 26s\n",
      "633:\tlearn: 0.0768550\ttotal: 14m 34s\tremaining: 8m 25s\n",
      "634:\tlearn: 0.0766314\ttotal: 14m 36s\tremaining: 8m 23s\n",
      "635:\tlearn: 0.0764375\ttotal: 14m 37s\tremaining: 8m 22s\n",
      "636:\tlearn: 0.0763637\ttotal: 14m 39s\tremaining: 8m 20s\n",
      "637:\tlearn: 0.0762551\ttotal: 14m 40s\tremaining: 8m 19s\n",
      "638:\tlearn: 0.0760187\ttotal: 14m 41s\tremaining: 8m 18s\n",
      "639:\tlearn: 0.0758556\ttotal: 14m 43s\tremaining: 8m 16s\n",
      "640:\tlearn: 0.0757208\ttotal: 14m 44s\tremaining: 8m 15s\n",
      "641:\tlearn: 0.0755740\ttotal: 14m 46s\tremaining: 8m 14s\n",
      "642:\tlearn: 0.0753718\ttotal: 14m 47s\tremaining: 8m 12s\n",
      "643:\tlearn: 0.0751761\ttotal: 14m 48s\tremaining: 8m 11s\n",
      "644:\tlearn: 0.0750057\ttotal: 14m 50s\tremaining: 8m 9s\n",
      "645:\tlearn: 0.0748267\ttotal: 14m 51s\tremaining: 8m 8s\n",
      "646:\tlearn: 0.0745701\ttotal: 14m 52s\tremaining: 8m 7s\n",
      "647:\tlearn: 0.0743756\ttotal: 14m 54s\tremaining: 8m 5s\n",
      "648:\tlearn: 0.0741800\ttotal: 14m 55s\tremaining: 8m 4s\n",
      "649:\tlearn: 0.0740626\ttotal: 14m 57s\tremaining: 8m 3s\n",
      "650:\tlearn: 0.0737939\ttotal: 14m 58s\tremaining: 8m 1s\n",
      "651:\tlearn: 0.0735891\ttotal: 14m 59s\tremaining: 8m\n",
      "652:\tlearn: 0.0733665\ttotal: 15m 1s\tremaining: 7m 58s\n",
      "653:\tlearn: 0.0732142\ttotal: 15m 2s\tremaining: 7m 57s\n",
      "654:\tlearn: 0.0729987\ttotal: 15m 3s\tremaining: 7m 56s\n",
      "655:\tlearn: 0.0727433\ttotal: 15m 5s\tremaining: 7m 54s\n",
      "656:\tlearn: 0.0725994\ttotal: 15m 6s\tremaining: 7m 53s\n",
      "657:\tlearn: 0.0724330\ttotal: 15m 7s\tremaining: 7m 51s\n",
      "658:\tlearn: 0.0722884\ttotal: 15m 9s\tremaining: 7m 50s\n",
      "659:\tlearn: 0.0721455\ttotal: 15m 10s\tremaining: 7m 49s\n",
      "660:\tlearn: 0.0719853\ttotal: 15m 11s\tremaining: 7m 47s\n",
      "661:\tlearn: 0.0718949\ttotal: 15m 13s\tremaining: 7m 46s\n",
      "662:\tlearn: 0.0717302\ttotal: 15m 14s\tremaining: 7m 44s\n",
      "663:\tlearn: 0.0715952\ttotal: 15m 15s\tremaining: 7m 43s\n",
      "664:\tlearn: 0.0714012\ttotal: 15m 16s\tremaining: 7m 41s\n",
      "665:\tlearn: 0.0712171\ttotal: 15m 18s\tremaining: 7m 40s\n",
      "666:\tlearn: 0.0710197\ttotal: 15m 19s\tremaining: 7m 39s\n",
      "667:\tlearn: 0.0708346\ttotal: 15m 20s\tremaining: 7m 37s\n",
      "668:\tlearn: 0.0706544\ttotal: 15m 22s\tremaining: 7m 36s\n",
      "669:\tlearn: 0.0705369\ttotal: 15m 23s\tremaining: 7m 34s\n",
      "670:\tlearn: 0.0704098\ttotal: 15m 24s\tremaining: 7m 33s\n",
      "671:\tlearn: 0.0702959\ttotal: 15m 25s\tremaining: 7m 31s\n",
      "672:\tlearn: 0.0701571\ttotal: 15m 27s\tremaining: 7m 30s\n",
      "673:\tlearn: 0.0700137\ttotal: 15m 28s\tremaining: 7m 29s\n",
      "674:\tlearn: 0.0698558\ttotal: 15m 29s\tremaining: 7m 27s\n",
      "675:\tlearn: 0.0696911\ttotal: 15m 31s\tremaining: 7m 26s\n",
      "676:\tlearn: 0.0695119\ttotal: 15m 32s\tremaining: 7m 24s\n",
      "677:\tlearn: 0.0693338\ttotal: 15m 33s\tremaining: 7m 23s\n",
      "678:\tlearn: 0.0691914\ttotal: 15m 35s\tremaining: 7m 22s\n",
      "679:\tlearn: 0.0690271\ttotal: 15m 36s\tremaining: 7m 20s\n",
      "680:\tlearn: 0.0688878\ttotal: 15m 37s\tremaining: 7m 19s\n",
      "681:\tlearn: 0.0687238\ttotal: 15m 39s\tremaining: 7m 17s\n",
      "682:\tlearn: 0.0686062\ttotal: 15m 40s\tremaining: 7m 16s\n",
      "683:\tlearn: 0.0684336\ttotal: 15m 41s\tremaining: 7m 15s\n",
      "684:\tlearn: 0.0682882\ttotal: 15m 43s\tremaining: 7m 13s\n",
      "685:\tlearn: 0.0681824\ttotal: 15m 44s\tremaining: 7m 12s\n",
      "686:\tlearn: 0.0680566\ttotal: 15m 45s\tremaining: 7m 10s\n",
      "687:\tlearn: 0.0679439\ttotal: 15m 47s\tremaining: 7m 9s\n",
      "688:\tlearn: 0.0678291\ttotal: 15m 48s\tremaining: 7m 8s\n",
      "689:\tlearn: 0.0676688\ttotal: 15m 49s\tremaining: 7m 6s\n",
      "690:\tlearn: 0.0675339\ttotal: 15m 51s\tremaining: 7m 5s\n",
      "691:\tlearn: 0.0673304\ttotal: 15m 52s\tremaining: 7m 4s\n",
      "692:\tlearn: 0.0671528\ttotal: 15m 54s\tremaining: 7m 2s\n",
      "693:\tlearn: 0.0669973\ttotal: 15m 55s\tremaining: 7m 1s\n",
      "694:\tlearn: 0.0668752\ttotal: 15m 56s\tremaining: 6m 59s\n",
      "695:\tlearn: 0.0667437\ttotal: 15m 58s\tremaining: 6m 58s\n",
      "696:\tlearn: 0.0666051\ttotal: 15m 59s\tremaining: 6m 57s\n",
      "697:\tlearn: 0.0664528\ttotal: 16m\tremaining: 6m 55s\n",
      "698:\tlearn: 0.0663457\ttotal: 16m 2s\tremaining: 6m 54s\n",
      "699:\tlearn: 0.0662583\ttotal: 16m 3s\tremaining: 6m 53s\n",
      "700:\tlearn: 0.0661141\ttotal: 16m 5s\tremaining: 6m 51s\n",
      "701:\tlearn: 0.0659696\ttotal: 16m 6s\tremaining: 6m 50s\n",
      "702:\tlearn: 0.0658408\ttotal: 16m 7s\tremaining: 6m 48s\n",
      "703:\tlearn: 0.0656492\ttotal: 16m 9s\tremaining: 6m 47s\n",
      "704:\tlearn: 0.0654891\ttotal: 16m 10s\tremaining: 6m 46s\n",
      "705:\tlearn: 0.0653680\ttotal: 16m 11s\tremaining: 6m 44s\n",
      "706:\tlearn: 0.0652345\ttotal: 16m 13s\tremaining: 6m 43s\n",
      "707:\tlearn: 0.0651005\ttotal: 16m 14s\tremaining: 6m 41s\n",
      "708:\tlearn: 0.0649470\ttotal: 16m 15s\tremaining: 6m 40s\n",
      "709:\tlearn: 0.0647683\ttotal: 16m 17s\tremaining: 6m 39s\n",
      "710:\tlearn: 0.0646083\ttotal: 16m 18s\tremaining: 6m 37s\n",
      "711:\tlearn: 0.0645082\ttotal: 16m 19s\tremaining: 6m 36s\n",
      "712:\tlearn: 0.0643635\ttotal: 16m 21s\tremaining: 6m 34s\n",
      "713:\tlearn: 0.0642142\ttotal: 16m 22s\tremaining: 6m 33s\n",
      "714:\tlearn: 0.0640856\ttotal: 16m 23s\tremaining: 6m 32s\n",
      "715:\tlearn: 0.0639631\ttotal: 16m 24s\tremaining: 6m 30s\n",
      "716:\tlearn: 0.0638671\ttotal: 16m 26s\tremaining: 6m 29s\n",
      "717:\tlearn: 0.0636714\ttotal: 16m 27s\tremaining: 6m 27s\n",
      "718:\tlearn: 0.0635396\ttotal: 16m 28s\tremaining: 6m 26s\n",
      "719:\tlearn: 0.0634214\ttotal: 16m 30s\tremaining: 6m 25s\n",
      "720:\tlearn: 0.0633163\ttotal: 16m 31s\tremaining: 6m 23s\n",
      "721:\tlearn: 0.0632541\ttotal: 16m 32s\tremaining: 6m 22s\n",
      "722:\tlearn: 0.0631280\ttotal: 16m 33s\tremaining: 6m 20s\n",
      "723:\tlearn: 0.0629462\ttotal: 16m 35s\tremaining: 6m 19s\n",
      "724:\tlearn: 0.0627800\ttotal: 16m 36s\tremaining: 6m 18s\n",
      "725:\tlearn: 0.0626254\ttotal: 16m 37s\tremaining: 6m 16s\n",
      "726:\tlearn: 0.0624836\ttotal: 16m 39s\tremaining: 6m 15s\n",
      "727:\tlearn: 0.0623506\ttotal: 16m 40s\tremaining: 6m 13s\n",
      "728:\tlearn: 0.0622246\ttotal: 16m 41s\tremaining: 6m 12s\n",
      "729:\tlearn: 0.0620874\ttotal: 16m 43s\tremaining: 6m 11s\n",
      "730:\tlearn: 0.0619567\ttotal: 16m 44s\tremaining: 6m 9s\n",
      "731:\tlearn: 0.0618201\ttotal: 16m 45s\tremaining: 6m 8s\n",
      "732:\tlearn: 0.0616940\ttotal: 16m 47s\tremaining: 6m 6s\n",
      "733:\tlearn: 0.0615759\ttotal: 16m 48s\tremaining: 6m 5s\n",
      "734:\tlearn: 0.0615008\ttotal: 16m 49s\tremaining: 6m 4s\n",
      "735:\tlearn: 0.0613370\ttotal: 16m 51s\tremaining: 6m 2s\n",
      "736:\tlearn: 0.0612059\ttotal: 16m 52s\tremaining: 6m 1s\n",
      "737:\tlearn: 0.0610857\ttotal: 16m 54s\tremaining: 6m\n",
      "738:\tlearn: 0.0609525\ttotal: 16m 55s\tremaining: 5m 58s\n",
      "739:\tlearn: 0.0608277\ttotal: 16m 57s\tremaining: 5m 57s\n",
      "740:\tlearn: 0.0606842\ttotal: 16m 58s\tremaining: 5m 55s\n",
      "741:\tlearn: 0.0605623\ttotal: 16m 59s\tremaining: 5m 54s\n",
      "742:\tlearn: 0.0604313\ttotal: 17m 1s\tremaining: 5m 53s\n",
      "743:\tlearn: 0.0603140\ttotal: 17m 2s\tremaining: 5m 51s\n",
      "744:\tlearn: 0.0602118\ttotal: 17m 4s\tremaining: 5m 50s\n",
      "745:\tlearn: 0.0600930\ttotal: 17m 5s\tremaining: 5m 49s\n",
      "746:\tlearn: 0.0599928\ttotal: 17m 7s\tremaining: 5m 47s\n",
      "747:\tlearn: 0.0598724\ttotal: 17m 8s\tremaining: 5m 46s\n",
      "748:\tlearn: 0.0597270\ttotal: 17m 9s\tremaining: 5m 45s\n",
      "749:\tlearn: 0.0595842\ttotal: 17m 11s\tremaining: 5m 43s\n",
      "750:\tlearn: 0.0594774\ttotal: 17m 12s\tremaining: 5m 42s\n",
      "751:\tlearn: 0.0593229\ttotal: 17m 13s\tremaining: 5m 40s\n",
      "752:\tlearn: 0.0591989\ttotal: 17m 15s\tremaining: 5m 39s\n",
      "753:\tlearn: 0.0590998\ttotal: 17m 16s\tremaining: 5m 38s\n",
      "754:\tlearn: 0.0589518\ttotal: 17m 18s\tremaining: 5m 36s\n",
      "755:\tlearn: 0.0588379\ttotal: 17m 19s\tremaining: 5m 35s\n",
      "756:\tlearn: 0.0586929\ttotal: 17m 20s\tremaining: 5m 34s\n",
      "757:\tlearn: 0.0585642\ttotal: 17m 22s\tremaining: 5m 32s\n",
      "758:\tlearn: 0.0584362\ttotal: 17m 23s\tremaining: 5m 31s\n",
      "759:\tlearn: 0.0583118\ttotal: 17m 25s\tremaining: 5m 30s\n",
      "760:\tlearn: 0.0581924\ttotal: 17m 26s\tremaining: 5m 28s\n",
      "761:\tlearn: 0.0580733\ttotal: 17m 28s\tremaining: 5m 27s\n",
      "762:\tlearn: 0.0579697\ttotal: 17m 29s\tremaining: 5m 25s\n",
      "763:\tlearn: 0.0578811\ttotal: 17m 30s\tremaining: 5m 24s\n",
      "764:\tlearn: 0.0577319\ttotal: 17m 32s\tremaining: 5m 23s\n",
      "765:\tlearn: 0.0576527\ttotal: 17m 33s\tremaining: 5m 21s\n",
      "766:\tlearn: 0.0575470\ttotal: 17m 34s\tremaining: 5m 20s\n",
      "767:\tlearn: 0.0573880\ttotal: 17m 36s\tremaining: 5m 19s\n",
      "768:\tlearn: 0.0573144\ttotal: 17m 37s\tremaining: 5m 17s\n",
      "769:\tlearn: 0.0571833\ttotal: 17m 39s\tremaining: 5m 16s\n",
      "770:\tlearn: 0.0570618\ttotal: 17m 40s\tremaining: 5m 15s\n",
      "771:\tlearn: 0.0569373\ttotal: 17m 41s\tremaining: 5m 13s\n",
      "772:\tlearn: 0.0568216\ttotal: 17m 43s\tremaining: 5m 12s\n",
      "773:\tlearn: 0.0566432\ttotal: 17m 44s\tremaining: 5m 10s\n",
      "774:\tlearn: 0.0565532\ttotal: 17m 46s\tremaining: 5m 9s\n",
      "775:\tlearn: 0.0564269\ttotal: 17m 47s\tremaining: 5m 8s\n",
      "776:\tlearn: 0.0563461\ttotal: 17m 48s\tremaining: 5m 6s\n",
      "777:\tlearn: 0.0562449\ttotal: 17m 50s\tremaining: 5m 5s\n",
      "778:\tlearn: 0.0561240\ttotal: 17m 51s\tremaining: 5m 4s\n",
      "779:\tlearn: 0.0560417\ttotal: 17m 53s\tremaining: 5m 2s\n",
      "780:\tlearn: 0.0559430\ttotal: 17m 54s\tremaining: 5m 1s\n",
      "781:\tlearn: 0.0558327\ttotal: 17m 55s\tremaining: 4m 59s\n",
      "782:\tlearn: 0.0557048\ttotal: 17m 57s\tremaining: 4m 58s\n",
      "783:\tlearn: 0.0556190\ttotal: 17m 58s\tremaining: 4m 57s\n",
      "784:\tlearn: 0.0555333\ttotal: 18m\tremaining: 4m 55s\n",
      "785:\tlearn: 0.0554574\ttotal: 18m 1s\tremaining: 4m 54s\n",
      "786:\tlearn: 0.0552864\ttotal: 18m 2s\tremaining: 4m 53s\n",
      "787:\tlearn: 0.0551395\ttotal: 18m 4s\tremaining: 4m 51s\n",
      "788:\tlearn: 0.0550055\ttotal: 18m 5s\tremaining: 4m 50s\n",
      "789:\tlearn: 0.0548630\ttotal: 18m 6s\tremaining: 4m 48s\n",
      "790:\tlearn: 0.0547659\ttotal: 18m 7s\tremaining: 4m 47s\n",
      "791:\tlearn: 0.0546470\ttotal: 18m 9s\tremaining: 4m 46s\n",
      "792:\tlearn: 0.0544984\ttotal: 18m 10s\tremaining: 4m 44s\n",
      "793:\tlearn: 0.0543904\ttotal: 18m 11s\tremaining: 4m 43s\n",
      "794:\tlearn: 0.0542829\ttotal: 18m 13s\tremaining: 4m 41s\n",
      "795:\tlearn: 0.0541673\ttotal: 18m 14s\tremaining: 4m 40s\n",
      "796:\tlearn: 0.0541243\ttotal: 18m 15s\tremaining: 4m 39s\n",
      "797:\tlearn: 0.0540323\ttotal: 18m 17s\tremaining: 4m 37s\n",
      "798:\tlearn: 0.0539437\ttotal: 18m 18s\tremaining: 4m 36s\n",
      "799:\tlearn: 0.0538298\ttotal: 18m 19s\tremaining: 4m 34s\n",
      "800:\tlearn: 0.0537197\ttotal: 18m 21s\tremaining: 4m 33s\n",
      "801:\tlearn: 0.0536700\ttotal: 18m 22s\tremaining: 4m 32s\n",
      "802:\tlearn: 0.0535503\ttotal: 18m 23s\tremaining: 4m 30s\n",
      "803:\tlearn: 0.0534739\ttotal: 18m 25s\tremaining: 4m 29s\n",
      "804:\tlearn: 0.0533543\ttotal: 18m 26s\tremaining: 4m 28s\n",
      "805:\tlearn: 0.0532405\ttotal: 18m 28s\tremaining: 4m 26s\n",
      "806:\tlearn: 0.0531538\ttotal: 18m 29s\tremaining: 4m 25s\n",
      "807:\tlearn: 0.0530388\ttotal: 18m 31s\tremaining: 4m 24s\n",
      "808:\tlearn: 0.0529553\ttotal: 18m 32s\tremaining: 4m 22s\n",
      "809:\tlearn: 0.0528729\ttotal: 18m 34s\tremaining: 4m 21s\n",
      "810:\tlearn: 0.0527448\ttotal: 18m 35s\tremaining: 4m 19s\n",
      "811:\tlearn: 0.0526744\ttotal: 18m 36s\tremaining: 4m 18s\n",
      "812:\tlearn: 0.0526001\ttotal: 18m 38s\tremaining: 4m 17s\n",
      "813:\tlearn: 0.0525024\ttotal: 18m 39s\tremaining: 4m 15s\n",
      "814:\tlearn: 0.0524299\ttotal: 18m 41s\tremaining: 4m 14s\n",
      "815:\tlearn: 0.0523321\ttotal: 18m 42s\tremaining: 4m 13s\n",
      "816:\tlearn: 0.0522152\ttotal: 18m 44s\tremaining: 4m 11s\n",
      "817:\tlearn: 0.0520952\ttotal: 18m 45s\tremaining: 4m 10s\n",
      "818:\tlearn: 0.0519897\ttotal: 18m 46s\tremaining: 4m 9s\n",
      "819:\tlearn: 0.0518545\ttotal: 18m 48s\tremaining: 4m 7s\n",
      "820:\tlearn: 0.0517582\ttotal: 18m 49s\tremaining: 4m 6s\n",
      "821:\tlearn: 0.0516538\ttotal: 18m 51s\tremaining: 4m 4s\n",
      "822:\tlearn: 0.0515669\ttotal: 18m 52s\tremaining: 4m 3s\n",
      "823:\tlearn: 0.0514814\ttotal: 18m 54s\tremaining: 4m 2s\n",
      "824:\tlearn: 0.0513956\ttotal: 18m 55s\tremaining: 4m\n",
      "825:\tlearn: 0.0512951\ttotal: 18m 56s\tremaining: 3m 59s\n",
      "826:\tlearn: 0.0511520\ttotal: 18m 57s\tremaining: 3m 58s\n",
      "827:\tlearn: 0.0510587\ttotal: 18m 59s\tremaining: 3m 56s\n",
      "828:\tlearn: 0.0509754\ttotal: 19m\tremaining: 3m 55s\n",
      "829:\tlearn: 0.0508786\ttotal: 19m 1s\tremaining: 3m 53s\n",
      "830:\tlearn: 0.0507980\ttotal: 19m 3s\tremaining: 3m 52s\n",
      "831:\tlearn: 0.0507212\ttotal: 19m 4s\tremaining: 3m 51s\n",
      "832:\tlearn: 0.0506262\ttotal: 19m 5s\tremaining: 3m 49s\n",
      "833:\tlearn: 0.0505278\ttotal: 19m 6s\tremaining: 3m 48s\n",
      "834:\tlearn: 0.0504503\ttotal: 19m 8s\tremaining: 3m 46s\n",
      "835:\tlearn: 0.0503663\ttotal: 19m 9s\tremaining: 3m 45s\n",
      "836:\tlearn: 0.0502833\ttotal: 19m 10s\tremaining: 3m 44s\n",
      "837:\tlearn: 0.0501896\ttotal: 19m 11s\tremaining: 3m 42s\n",
      "838:\tlearn: 0.0500850\ttotal: 19m 13s\tremaining: 3m 41s\n",
      "839:\tlearn: 0.0499946\ttotal: 19m 14s\tremaining: 3m 39s\n",
      "840:\tlearn: 0.0498983\ttotal: 19m 15s\tremaining: 3m 38s\n",
      "841:\tlearn: 0.0498276\ttotal: 19m 16s\tremaining: 3m 37s\n",
      "842:\tlearn: 0.0497366\ttotal: 19m 18s\tremaining: 3m 35s\n",
      "843:\tlearn: 0.0496350\ttotal: 19m 19s\tremaining: 3m 34s\n",
      "844:\tlearn: 0.0495414\ttotal: 19m 20s\tremaining: 3m 32s\n",
      "845:\tlearn: 0.0494723\ttotal: 19m 22s\tremaining: 3m 31s\n",
      "846:\tlearn: 0.0493653\ttotal: 19m 23s\tremaining: 3m 30s\n",
      "847:\tlearn: 0.0492903\ttotal: 19m 24s\tremaining: 3m 28s\n",
      "848:\tlearn: 0.0492103\ttotal: 19m 25s\tremaining: 3m 27s\n",
      "849:\tlearn: 0.0491589\ttotal: 19m 27s\tremaining: 3m 25s\n",
      "850:\tlearn: 0.0490904\ttotal: 19m 28s\tremaining: 3m 24s\n",
      "851:\tlearn: 0.0489847\ttotal: 19m 29s\tremaining: 3m 23s\n",
      "852:\tlearn: 0.0488867\ttotal: 19m 30s\tremaining: 3m 21s\n",
      "853:\tlearn: 0.0487848\ttotal: 19m 32s\tremaining: 3m 20s\n",
      "854:\tlearn: 0.0486664\ttotal: 19m 33s\tremaining: 3m 19s\n",
      "855:\tlearn: 0.0485843\ttotal: 19m 34s\tremaining: 3m 17s\n",
      "856:\tlearn: 0.0484919\ttotal: 19m 36s\tremaining: 3m 16s\n",
      "857:\tlearn: 0.0484022\ttotal: 19m 37s\tremaining: 3m 14s\n",
      "858:\tlearn: 0.0483281\ttotal: 19m 38s\tremaining: 3m 13s\n",
      "859:\tlearn: 0.0482476\ttotal: 19m 39s\tremaining: 3m 12s\n",
      "860:\tlearn: 0.0481748\ttotal: 19m 41s\tremaining: 3m 10s\n",
      "861:\tlearn: 0.0480599\ttotal: 19m 42s\tremaining: 3m 9s\n",
      "862:\tlearn: 0.0480005\ttotal: 19m 43s\tremaining: 3m 7s\n",
      "863:\tlearn: 0.0479531\ttotal: 19m 44s\tremaining: 3m 6s\n",
      "864:\tlearn: 0.0478881\ttotal: 19m 46s\tremaining: 3m 5s\n",
      "865:\tlearn: 0.0478251\ttotal: 19m 47s\tremaining: 3m 3s\n",
      "866:\tlearn: 0.0477720\ttotal: 19m 48s\tremaining: 3m 2s\n",
      "867:\tlearn: 0.0476920\ttotal: 19m 50s\tremaining: 3m\n",
      "868:\tlearn: 0.0475964\ttotal: 19m 51s\tremaining: 2m 59s\n",
      "869:\tlearn: 0.0475214\ttotal: 19m 52s\tremaining: 2m 58s\n",
      "870:\tlearn: 0.0474241\ttotal: 19m 53s\tremaining: 2m 56s\n",
      "871:\tlearn: 0.0473762\ttotal: 19m 55s\tremaining: 2m 55s\n",
      "872:\tlearn: 0.0472936\ttotal: 19m 56s\tremaining: 2m 54s\n",
      "873:\tlearn: 0.0472290\ttotal: 19m 57s\tremaining: 2m 52s\n",
      "874:\tlearn: 0.0471582\ttotal: 19m 58s\tremaining: 2m 51s\n",
      "875:\tlearn: 0.0470824\ttotal: 20m\tremaining: 2m 49s\n",
      "876:\tlearn: 0.0470000\ttotal: 20m 1s\tremaining: 2m 48s\n",
      "877:\tlearn: 0.0469117\ttotal: 20m 2s\tremaining: 2m 47s\n",
      "878:\tlearn: 0.0468078\ttotal: 20m 4s\tremaining: 2m 45s\n",
      "879:\tlearn: 0.0467317\ttotal: 20m 5s\tremaining: 2m 44s\n",
      "880:\tlearn: 0.0466640\ttotal: 20m 6s\tremaining: 2m 42s\n",
      "881:\tlearn: 0.0465859\ttotal: 20m 7s\tremaining: 2m 41s\n",
      "882:\tlearn: 0.0464952\ttotal: 20m 9s\tremaining: 2m 40s\n",
      "883:\tlearn: 0.0464018\ttotal: 20m 10s\tremaining: 2m 38s\n",
      "884:\tlearn: 0.0463215\ttotal: 20m 11s\tremaining: 2m 37s\n",
      "885:\tlearn: 0.0462357\ttotal: 20m 13s\tremaining: 2m 36s\n",
      "886:\tlearn: 0.0461575\ttotal: 20m 14s\tremaining: 2m 34s\n",
      "887:\tlearn: 0.0460530\ttotal: 20m 15s\tremaining: 2m 33s\n",
      "888:\tlearn: 0.0459641\ttotal: 20m 16s\tremaining: 2m 31s\n",
      "889:\tlearn: 0.0458955\ttotal: 20m 18s\tremaining: 2m 30s\n",
      "890:\tlearn: 0.0458309\ttotal: 20m 19s\tremaining: 2m 29s\n",
      "891:\tlearn: 0.0457430\ttotal: 20m 20s\tremaining: 2m 27s\n",
      "892:\tlearn: 0.0456590\ttotal: 20m 22s\tremaining: 2m 26s\n",
      "893:\tlearn: 0.0455888\ttotal: 20m 23s\tremaining: 2m 25s\n",
      "894:\tlearn: 0.0455117\ttotal: 20m 24s\tremaining: 2m 23s\n",
      "895:\tlearn: 0.0454600\ttotal: 20m 25s\tremaining: 2m 22s\n",
      "896:\tlearn: 0.0453494\ttotal: 20m 27s\tremaining: 2m 20s\n",
      "897:\tlearn: 0.0452659\ttotal: 20m 28s\tremaining: 2m 19s\n",
      "898:\tlearn: 0.0452039\ttotal: 20m 29s\tremaining: 2m 18s\n",
      "899:\tlearn: 0.0451821\ttotal: 20m 30s\tremaining: 2m 16s\n",
      "900:\tlearn: 0.0450974\ttotal: 20m 32s\tremaining: 2m 15s\n",
      "901:\tlearn: 0.0450584\ttotal: 20m 33s\tremaining: 2m 14s\n",
      "902:\tlearn: 0.0449818\ttotal: 20m 34s\tremaining: 2m 12s\n",
      "903:\tlearn: 0.0449144\ttotal: 20m 35s\tremaining: 2m 11s\n",
      "904:\tlearn: 0.0448556\ttotal: 20m 37s\tremaining: 2m 9s\n",
      "905:\tlearn: 0.0447879\ttotal: 20m 38s\tremaining: 2m 8s\n",
      "906:\tlearn: 0.0446885\ttotal: 20m 39s\tremaining: 2m 7s\n",
      "907:\tlearn: 0.0445853\ttotal: 20m 40s\tremaining: 2m 5s\n",
      "908:\tlearn: 0.0445307\ttotal: 20m 42s\tremaining: 2m 4s\n",
      "909:\tlearn: 0.0444302\ttotal: 20m 43s\tremaining: 2m 2s\n",
      "910:\tlearn: 0.0443427\ttotal: 20m 44s\tremaining: 2m 1s\n",
      "911:\tlearn: 0.0442680\ttotal: 20m 45s\tremaining: 2m\n",
      "912:\tlearn: 0.0441977\ttotal: 20m 47s\tremaining: 1m 58s\n",
      "913:\tlearn: 0.0441469\ttotal: 20m 48s\tremaining: 1m 57s\n",
      "914:\tlearn: 0.0440769\ttotal: 20m 49s\tremaining: 1m 56s\n",
      "915:\tlearn: 0.0440062\ttotal: 20m 51s\tremaining: 1m 54s\n",
      "916:\tlearn: 0.0439201\ttotal: 20m 52s\tremaining: 1m 53s\n",
      "917:\tlearn: 0.0438526\ttotal: 20m 53s\tremaining: 1m 51s\n",
      "918:\tlearn: 0.0437922\ttotal: 20m 55s\tremaining: 1m 50s\n",
      "919:\tlearn: 0.0437379\ttotal: 20m 56s\tremaining: 1m 49s\n",
      "920:\tlearn: 0.0436239\ttotal: 20m 57s\tremaining: 1m 47s\n",
      "921:\tlearn: 0.0435732\ttotal: 20m 58s\tremaining: 1m 46s\n",
      "922:\tlearn: 0.0435015\ttotal: 21m\tremaining: 1m 45s\n",
      "923:\tlearn: 0.0434692\ttotal: 21m 1s\tremaining: 1m 43s\n",
      "924:\tlearn: 0.0434091\ttotal: 21m 2s\tremaining: 1m 42s\n",
      "925:\tlearn: 0.0433423\ttotal: 21m 4s\tremaining: 1m 41s\n",
      "926:\tlearn: 0.0433001\ttotal: 21m 5s\tremaining: 1m 39s\n",
      "927:\tlearn: 0.0432318\ttotal: 21m 6s\tremaining: 1m 38s\n",
      "928:\tlearn: 0.0431504\ttotal: 21m 7s\tremaining: 1m 36s\n",
      "929:\tlearn: 0.0430706\ttotal: 21m 9s\tremaining: 1m 35s\n",
      "930:\tlearn: 0.0429793\ttotal: 21m 10s\tremaining: 1m 34s\n",
      "931:\tlearn: 0.0429439\ttotal: 21m 11s\tremaining: 1m 32s\n",
      "932:\tlearn: 0.0428751\ttotal: 21m 13s\tremaining: 1m 31s\n",
      "933:\tlearn: 0.0427984\ttotal: 21m 14s\tremaining: 1m 30s\n",
      "934:\tlearn: 0.0427400\ttotal: 21m 15s\tremaining: 1m 28s\n",
      "935:\tlearn: 0.0426961\ttotal: 21m 17s\tremaining: 1m 27s\n",
      "936:\tlearn: 0.0426254\ttotal: 21m 18s\tremaining: 1m 25s\n",
      "937:\tlearn: 0.0425796\ttotal: 21m 19s\tremaining: 1m 24s\n",
      "938:\tlearn: 0.0425319\ttotal: 21m 20s\tremaining: 1m 23s\n",
      "939:\tlearn: 0.0424579\ttotal: 21m 22s\tremaining: 1m 21s\n",
      "940:\tlearn: 0.0423944\ttotal: 21m 23s\tremaining: 1m 20s\n",
      "941:\tlearn: 0.0423150\ttotal: 21m 24s\tremaining: 1m 19s\n",
      "942:\tlearn: 0.0422444\ttotal: 21m 26s\tremaining: 1m 17s\n",
      "943:\tlearn: 0.0421572\ttotal: 21m 27s\tremaining: 1m 16s\n",
      "944:\tlearn: 0.0420833\ttotal: 21m 28s\tremaining: 1m 15s\n",
      "945:\tlearn: 0.0420225\ttotal: 21m 30s\tremaining: 1m 13s\n",
      "946:\tlearn: 0.0419194\ttotal: 21m 31s\tremaining: 1m 12s\n",
      "947:\tlearn: 0.0418707\ttotal: 21m 32s\tremaining: 1m 10s\n",
      "948:\tlearn: 0.0417863\ttotal: 21m 34s\tremaining: 1m 9s\n",
      "949:\tlearn: 0.0417179\ttotal: 21m 35s\tremaining: 1m 8s\n",
      "950:\tlearn: 0.0416700\ttotal: 21m 36s\tremaining: 1m 6s\n",
      "951:\tlearn: 0.0415966\ttotal: 21m 37s\tremaining: 1m 5s\n",
      "952:\tlearn: 0.0415299\ttotal: 21m 39s\tremaining: 1m 4s\n",
      "953:\tlearn: 0.0414521\ttotal: 21m 40s\tremaining: 1m 2s\n",
      "954:\tlearn: 0.0413806\ttotal: 21m 41s\tremaining: 1m 1s\n",
      "955:\tlearn: 0.0413481\ttotal: 21m 43s\tremaining: 60s\n",
      "956:\tlearn: 0.0413063\ttotal: 21m 44s\tremaining: 58.6s\n",
      "957:\tlearn: 0.0412201\ttotal: 21m 45s\tremaining: 57.2s\n",
      "958:\tlearn: 0.0411567\ttotal: 21m 47s\tremaining: 55.9s\n",
      "959:\tlearn: 0.0410992\ttotal: 21m 48s\tremaining: 54.5s\n",
      "960:\tlearn: 0.0410297\ttotal: 21m 49s\tremaining: 53.1s\n",
      "961:\tlearn: 0.0409496\ttotal: 21m 50s\tremaining: 51.8s\n",
      "962:\tlearn: 0.0408953\ttotal: 21m 52s\tremaining: 50.4s\n",
      "963:\tlearn: 0.0408285\ttotal: 21m 53s\tremaining: 49s\n",
      "964:\tlearn: 0.0407585\ttotal: 21m 54s\tremaining: 47.7s\n",
      "965:\tlearn: 0.0406919\ttotal: 21m 55s\tremaining: 46.3s\n",
      "966:\tlearn: 0.0406487\ttotal: 21m 57s\tremaining: 45s\n",
      "967:\tlearn: 0.0405833\ttotal: 21m 58s\tremaining: 43.6s\n",
      "968:\tlearn: 0.0404881\ttotal: 21m 59s\tremaining: 42.2s\n",
      "969:\tlearn: 0.0404382\ttotal: 22m 1s\tremaining: 40.9s\n",
      "970:\tlearn: 0.0403743\ttotal: 22m 2s\tremaining: 39.5s\n",
      "971:\tlearn: 0.0403163\ttotal: 22m 3s\tremaining: 38.1s\n",
      "972:\tlearn: 0.0402757\ttotal: 22m 4s\tremaining: 36.8s\n",
      "973:\tlearn: 0.0402060\ttotal: 22m 6s\tremaining: 35.4s\n",
      "974:\tlearn: 0.0401453\ttotal: 22m 7s\tremaining: 34s\n",
      "975:\tlearn: 0.0400831\ttotal: 22m 8s\tremaining: 32.7s\n",
      "976:\tlearn: 0.0400138\ttotal: 22m 9s\tremaining: 31.3s\n",
      "977:\tlearn: 0.0399721\ttotal: 22m 11s\tremaining: 29.9s\n",
      "978:\tlearn: 0.0398940\ttotal: 22m 12s\tremaining: 28.6s\n",
      "979:\tlearn: 0.0398240\ttotal: 22m 13s\tremaining: 27.2s\n",
      "980:\tlearn: 0.0397822\ttotal: 22m 15s\tremaining: 25.9s\n",
      "981:\tlearn: 0.0396980\ttotal: 22m 16s\tremaining: 24.5s\n",
      "982:\tlearn: 0.0396399\ttotal: 22m 17s\tremaining: 23.1s\n",
      "983:\tlearn: 0.0395808\ttotal: 22m 18s\tremaining: 21.8s\n",
      "984:\tlearn: 0.0395310\ttotal: 22m 20s\tremaining: 20.4s\n",
      "985:\tlearn: 0.0394813\ttotal: 22m 21s\tremaining: 19s\n",
      "986:\tlearn: 0.0394183\ttotal: 22m 22s\tremaining: 17.7s\n",
      "987:\tlearn: 0.0393301\ttotal: 22m 24s\tremaining: 16.3s\n",
      "988:\tlearn: 0.0392698\ttotal: 22m 25s\tremaining: 15s\n",
      "989:\tlearn: 0.0392254\ttotal: 22m 26s\tremaining: 13.6s\n",
      "990:\tlearn: 0.0391795\ttotal: 22m 28s\tremaining: 12.2s\n",
      "991:\tlearn: 0.0391271\ttotal: 22m 29s\tremaining: 10.9s\n",
      "992:\tlearn: 0.0390572\ttotal: 22m 30s\tremaining: 9.52s\n",
      "993:\tlearn: 0.0389852\ttotal: 22m 31s\tremaining: 8.16s\n",
      "994:\tlearn: 0.0389312\ttotal: 22m 33s\tremaining: 6.8s\n",
      "995:\tlearn: 0.0388713\ttotal: 22m 34s\tremaining: 5.44s\n",
      "996:\tlearn: 0.0388000\ttotal: 22m 35s\tremaining: 4.08s\n",
      "997:\tlearn: 0.0387371\ttotal: 22m 36s\tremaining: 2.72s\n",
      "998:\tlearn: 0.0385864\ttotal: 22m 38s\tremaining: 1.36s\n",
      "999:\tlearn: 0.0385409\ttotal: 22m 39s\tremaining: 0us\n",
      "Field score: 1.2058022589781323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Crop_ID_1</th>\n",
       "      <th>Crop_ID_2</th>\n",
       "      <th>Crop_ID_3</th>\n",
       "      <th>Crop_ID_4</th>\n",
       "      <th>Crop_ID_5</th>\n",
       "      <th>Crop_ID_6</th>\n",
       "      <th>Crop_ID_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.958006</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.016829</td>\n",
       "      <td>0.976458</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>0.725322</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.185986</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.008960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.094694</td>\n",
       "      <td>0.874140</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.070260</td>\n",
       "      <td>0.753155</td>\n",
       "      <td>0.128786</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.003355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Field_ID  Crop_ID_1  Crop_ID_2  ...  Crop_ID_5  Crop_ID_6  Crop_ID_7\n",
       "0         3   0.015622   0.958006  ...   0.001333   0.002051   0.003773\n",
       "1         6   0.016829   0.976458  ...   0.001025   0.000946   0.000220\n",
       "2        11   0.038543   0.725322  ...   0.008211   0.007907   0.008960\n",
       "3        13   0.094694   0.874140  ...   0.005246   0.003706   0.001255\n",
       "4        14   0.070260   0.753155  ...   0.019958   0.003240   0.003355\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "train = df.loc[df.label != 0]\n",
    "test =  df.loc[df.label == 0]\n",
    "train.shape, test.shape\n",
    "# Split train into train and val, so that we can score our models locally (test is the test set)\n",
    "\n",
    "# Splitting on field ID since we want to predict for unseen FIELDS\n",
    "val_field_ids = train.groupby('fid').mean().reset_index()['fid'].sample(frac=0.3).values\n",
    "tr = train.loc[~train.fid.isin(val_field_ids)].copy()\n",
    "val = train.loc[train.fid.isin(val_field_ids)].copy()\n",
    "\n",
    "# Split into X and Y for modelling\n",
    "X_train, y_train = tr[tr.columns[5:]], tr['label']\n",
    "X_val, y_val = val[val.columns[5:]], val['label']\n",
    "# Predicting on fields (grouping first)\n",
    "\n",
    "# Group\n",
    "train_grouped = tr.groupby('fid').mean().reset_index()\n",
    "val_grouped = val.groupby('fid').mean().reset_index()\n",
    "X_train, y_train = train_grouped[train_grouped.columns[5:]], train_grouped['label']\n",
    "X_val, y_val = val_grouped[train_grouped.columns[5:]], val_grouped['label']\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model =  CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.1,\n",
    "    depth=8,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "preds = model.predict_proba(X_val.fillna(0))\n",
    "\n",
    "# Add to val_grouped dataframe as columns\n",
    "for i in range(7):\n",
    "      val_grouped[str(i+1)] = preds[:,i]\n",
    "\n",
    "# Get 'true' vals as columns in val\n",
    "for c in range(1, 8):\n",
    "      val_grouped['true'+str(c)] = (val_grouped['label'] == c).astype(int)\n",
    "\n",
    "pred_cols = [str(i) for i in range(1, 8)]\n",
    "true_cols = ['true'+str(i) for i in range(1, 8)]\n",
    "val_grouped[['label']+true_cols+pred_cols].head()\n",
    "\n",
    "# Already grouped, but just to double check:\n",
    "print('Field score:', log_loss(val_grouped.groupby('fid').mean()[true_cols], val_grouped.groupby('fid').mean()[pred_cols]))\n",
    "# Group test as we did for val\n",
    "test_grouped = test.groupby('fid').mean().reset_index()\n",
    "preds = model.predict_proba(test_grouped[train_grouped.columns[5:]])\n",
    "\n",
    "prob_df = pd.DataFrame({\n",
    "    'Field_ID':test_grouped['fid'].values\n",
    "})\n",
    "for c in range(1, 8):\n",
    "    prob_df['Crop_ID_'+str(c)] = preds[:,c-1]\n",
    "prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "6vIACzwRhs5b",
    "outputId": "3d97fee5-768c-48f9-c152-4ce0af2d6473"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Crop_ID_1</th>\n",
       "      <th>Crop_ID_2</th>\n",
       "      <th>Crop_ID_3</th>\n",
       "      <th>Crop_ID_4</th>\n",
       "      <th>Crop_ID_5</th>\n",
       "      <th>Crop_ID_6</th>\n",
       "      <th>Crop_ID_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Field_ID  Crop_ID_1  Crop_ID_2  ...  Crop_ID_5  Crop_ID_6  Crop_ID_7\n",
       "0         3          0          0  ...          0          0          0\n",
       "1         6          0          0  ...          0          0          0\n",
       "2        11          0          0  ...          0          0          0\n",
       "3        13          0          0  ...          0          0          0\n",
       "4        14          0          0  ...          0          0          0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sample submission and compare\n",
    "ss = pd.read_csv('SampleSubmission.csv')\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oj-nCvaVhs22",
    "outputId": "712c7298-4f8f-4423-c17f-8fd1a5f6a420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Merge the two, to get all the required field IDs\n",
    "ss = pd.merge(ss['Field_ID'], prob_df, how='left', on='Field_ID')\n",
    "print(ss.isna().sum()['Crop_ID_1']) # Missing fields\n",
    "# Fill in a low but non-zero val for the missing rows:\n",
    "ss = ss.fillna(1/7) # There are 34 missing fields\n",
    "ss.to_csv('Catboost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu68HRRylNn6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
